{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat Coverage Investigation\n",
    "\n",
    "https://towardsdatascience.com/downloading-landsat-satellite-images-with-python-a2d2b5183fb7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from landsatxplore.api import API\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.wkt\n",
    "import rasterio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from shapely.strtree import STRtree\n",
    "import datetime\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_shape = 'shapefiles/50south_excl_argentina_falkand_mid.geojson'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_landsat(df, max_date=''):\n",
    "    # DE - spatial\n",
    "    df['spatial_coverage'] = df['spatial_coverage'].apply(lambda x : shapely.wkt.loads(x))\n",
    "    df['geometry_4326'] = df['spatial_coverage'].copy()\n",
    "    # DE - Time\n",
    "    df['start_time'] = df['start_time'].apply(lambda x : str(x).split('.')[0])\n",
    "    df['start_time'] = pd.to_datetime(df['start_time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df['month'] = df['start_time'].dt.month\n",
    "    df['month_name'] = df['start_time'].dt.month_name()\n",
    "    df['year'] = df['start_time'].dt.year\n",
    "    # limit by max date\n",
    "    if max_date:\n",
    "        df = df[df['start_time'] < max_date]\n",
    "    # DE - Filesize by Satellite (https://www.usgs.gov/faqs/what-are-landsat-collection-1-level-1-data-product-file-sizes)\n",
    "    df['size_compressed_mb'] = df['satellite'].map({8:919,9:919,7:235,5:150,4:150,'LANDSAT_4':150, 'LANDSAT_5':150})\n",
    "    df['size_uncompressed_mb'] = df['satellite'].map({8:1610,9:1610,7:785,5:500,4:500,'LANDSAT_4':500, 'LANDSAT_5':500})\n",
    "    # DE - Sun Azumith\n",
    "    if 'sun_elevation_l0ra' in list(df):\n",
    "        df['sun_zenith_10ra'] = 90 - df['sun_elevation_l0ra'] \n",
    "    elif 'sun_elevation' in list(df):\n",
    "        df['sun_zenith'] = 90 - df['sun_elevation'] \n",
    "    # cloud cover categories - https://landsat.usgs.gov/landsat-8-cloud-cover-assessment-validation-data\n",
    "    df['cloud_cover_category'] = df['cloud_cover'].apply(lambda x : 'Clear (<35%)' if x < 35 else ('Cloudy (>65%)' if x>65 else 'MidClouds (35-65%)'))\n",
    "    # sat name\n",
    "    df['sat_id'] = df['satellite'].apply(lambda x : 'Landsat ' + str(x) if 'LAND' not in str(x) else 'Landsat ' + x.split('_')[-1])\n",
    "    # sat name 4/5 \n",
    "    # load into geopandas df and filter for AOI\n",
    "    df = gpd.GeoDataFrame(df, geometry='spatial_coverage', crs=\"EPSG:4326\")\n",
    "    df = df.to_crs(3031)\n",
    "    return df\n",
    "\n",
    "def plot_geometries_on_map(df, extent = (-180, 180, -90, -50)):\n",
    "    plt.rcParams[\"figure.figsize\"] = [14,6]\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.set_extent(extent, ccrs.PlateCarree())\n",
    "    ax.add_feature(cartopy.feature.LAND)\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    ax.add_geometries(df.geometry, \n",
    "                    crs=ccrs.SouthPolarStereo(), \n",
    "                    alpha=0.2)\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    plt.show()\n",
    "\n",
    "# limit by shapefile\n",
    "def filter_results_with_geojson(df, shape_filename, plot=False, crs=4326):\n",
    "    gdf_inclusion = gpd.read_file(shape_filename)\n",
    "    #df = df[df.intersects(gdf_inclusion.geometry.values[0])]\n",
    "    if crs == 4326:\n",
    "        df = df[df['geometry_4326'].apply(lambda x : x.intersects(gdf_inclusion.geometry.values[0]))]\n",
    "    else:\n",
    "        df = df[df.geometry.apply(lambda x : x.intersects(gdf_inclusion.geometry.values[0]))]\n",
    "    if plot:\n",
    "        plt.rcParams[\"figure.figsize\"] = [10,8]\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree(), title='Product Search Area - 50deg south excl. South America and Falkland Islands')\n",
    "        ax.add_feature(cartopy.feature.LAND)\n",
    "        ax.add_feature(cartopy.feature.OCEAN)\n",
    "        ax.add_geometries(gdf_inclusion.geometry, crs=ccrs.PlateCarree(), alpha=0.7)\n",
    "        plt.show()\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting - Timeseries Product Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_timeseries_products(df, title='',stack_col='sat_id', date_col='beginposition',count_freq='7D', plot_freq='1M'):\n",
    "    import seaborn as sns\n",
    "    sns.set_theme()\n",
    "    sns.set(rc={'figure.figsize':(10,2)})\n",
    "    df['round_time'] = df[date_col].dt.round(count_freq)\n",
    "    c = df[['round_time',stack_col,'entity_id']].groupby(['round_time',stack_col]).count().reset_index()\n",
    "    c = c.pivot(index='round_time', columns=stack_col, values='entity_id').fillna(0)\n",
    "    c = c.resample(plot_freq).max()\n",
    "    ax = c.plot(kind='bar', stacked=True, width=1)\n",
    "    import matplotlib.ticker as ticker\n",
    "    ticklabels = ['']\n",
    "    for i in range(1,len(c.index)):\n",
    "        ticklabels.append('') if c.index[i].year == c.index[i-1].year else ticklabels.append(c.index[i].year)\n",
    "    ax.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels))\n",
    "    ax.set_xlabel('')\n",
    "    plt.xticks(rotation = 45, fontsize='10')\n",
    "    plt.yticks(fontsize='10')\n",
    "    plt.legend(title='')\n",
    "    plt.title(title)\n",
    "    set(ticklabels)\n",
    "    sns.reset_orig()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting - WRS2 Grid Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mgrs_product_count(df, title=''):\n",
    "\n",
    "    #read in the mgrs tile \n",
    "    print('loading tile shapefile...')\n",
    "    if 'OLI' in df['sensor_id'].iloc[0]:\n",
    "        # landsat 8 and 9\n",
    "        if df.iloc[0]['day-night_indicator'] == 'DAY':\n",
    "            shp = 'shapefiles/WRS2_descending_0_daytime/WRS2_descending.shp'\n",
    "        elif df.iloc[0]['day-night_indicator'] == 'NIGHT':\n",
    "            shp = 'shapefiles/WRS2_ascending_0_nighttime/WRS2_ascending.shp'\n",
    "    if 'ETM' in df['sensor_id'].iloc[0]:\n",
    "        shp = 'shapefiles/WRS2_descending_0_daytime/WRS2_descending.shp'\n",
    "    \n",
    "    df_tiles = gpd.read_file(shp)\n",
    "\n",
    "    # product count\n",
    "    print('counting products')\n",
    "    prod_count = df.groupby(['wrs_path', 'wrs_row'])['landsat_product_id'].count().reset_index()\n",
    "    tile_count = prod_count.merge(df_tiles, right_on=['PATH','ROW'], left_on=['wrs_path', 'wrs_row'])\n",
    "    tile_count.set_geometry('geometry')\n",
    "    tile_count = tile_count.rename(columns={'landsat_product_id':'filecount'})\n",
    "    tile_count = tile_count.sort_values('filecount')\n",
    "    crs = ccrs.PlateCarree()\n",
    "    shape = 1000, 1000\n",
    "    bounds = crs.boundary.bounds\n",
    "    east, west, south, north = -180, 180, -90, -50\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "\n",
    "    import matplotlib.cm as cm\n",
    "\n",
    "    minima = tile_count.filecount.min()\n",
    "    maxima = tile_count.filecount.max()\n",
    "\n",
    "    norm = matplotlib.colors.Normalize(vmin=minima, vmax=maxima, clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap=cm.viridis)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = [10,8]\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.set_extent((east, west, south, north+1), ccrs.PlateCarree())\n",
    "    ax.add_feature(cartopy.feature.LAND)\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    count_vals = tile_count.filecount.values\n",
    "    c = []\n",
    "    for v in count_vals:\n",
    "        c.append(mapper.to_rgba(v))\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    ax.add_geometries(tile_count.geometry, crs=ccrs.PlateCarree(), alpha=0.5, facecolor=c)\n",
    "    ax.add_feature(cartopy.feature.COASTLINE)\n",
    "    plt.colorbar(mapper, label='Count of Products')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiple_product_count(df, group, title='', n_cols=2, cbar_label='Count of Products'):\n",
    "\n",
    "    #read in the mgrs tile \n",
    "    print('loading tile shapefile...')\n",
    "    if df.iloc[0]['day-night_indicator'] == 'DAY':\n",
    "        df_tiles = gpd.read_file('shapefiles/WRS2_descending_0_daytime/WRS2_descending.shp')\n",
    "    elif df.iloc[0]['day-night_indicator'] == 'NIGHT':\n",
    "        df_tiles = gpd.read_file('shapefiles/WRS2_ascending_0_nighttime/WRS2_ascending.shp')\n",
    "    \n",
    "    \n",
    "    # calculate the size of the figure\n",
    "    n = df[group].nunique()\n",
    "    n_rows = math.ceil(n/n_cols)\n",
    "\n",
    "    # using the variable axs for multiple Axes\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols,\n",
    "                        subplot_kw={'projection': ccrs.SouthPolarStereo()},\n",
    "                        figsize=(n_cols*5,n_rows*4.5))\n",
    "    \n",
    "    # product count by group to get max and min for colorbar\n",
    "    prod_counts = df.groupby([group] + ['wrs_path', 'wrs_row'])['landsat_product_id'].count().reset_index()\n",
    "    prod_counts = prod_counts.rename(columns={'landsat_product_id':'filecount'})\n",
    "    minima = prod_counts.filecount.min()\n",
    "    maxima = prod_counts.filecount.max()\n",
    "    import matplotlib.cm as cm\n",
    "\n",
    "    norm = matplotlib.colors.Normalize(vmin=minima, vmax=maxima, clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap=cm.viridis)\n",
    "    count = 0\n",
    "    \n",
    "    plot_grps = df[group].unique()\n",
    "    try:\n",
    "        # sort if numeric\n",
    "        int(plot_grps[0])\n",
    "        plot_grps = sorted(plot_grps)\n",
    "    except:\n",
    "        ...\n",
    "\n",
    "    for grp in plot_grps:\n",
    "        grp_df = df[df[group] == grp]\n",
    "        tile_count = grp_df.groupby([group] + ['wrs_path', 'wrs_row'])['landsat_product_id'].count().reset_index()\n",
    "        tile_count = tile_count.rename(columns={'landsat_product_id':'filecount'})\n",
    "        tile_count = tile_count.merge(df_tiles, right_on=['PATH','ROW'], left_on=['wrs_path', 'wrs_row']) \n",
    "        tile_count.set_geometry('geometry')\n",
    "        tile_count = tile_count.sort_values('filecount')\n",
    "        n_products = tile_count['filecount'].sum()\n",
    "        east, west, south, north = -180, 180, -90, -50\n",
    "        r = math.floor((count)/n_cols)\n",
    "        c = count % n_cols\n",
    "        ax_i = (r,c) if ((n_cols > 1) and (n_rows>1)) else count # only a single index needed if no cols\n",
    "        ax[ax_i].set_extent((east, west, south, north), ccrs.PlateCarree())\n",
    "        ax[ax_i].add_feature(cartopy.feature.LAND)\n",
    "        ax[ax_i].add_feature(cartopy.feature.OCEAN)\n",
    "        subtitle = f'{grp} ({n_products:,} products)'\n",
    "        ax[ax_i].title.set_text(subtitle)\n",
    "        print(subtitle)\n",
    "        count_vals = tile_count.filecount.values\n",
    "        c = []\n",
    "        for v in count_vals:\n",
    "            c.append(mapper.to_rgba(v))\n",
    "        ax[ax_i].add_geometries(tile_count.geometry, crs=ccrs.PlateCarree(), alpha=0.8, facecolor=c)\n",
    "        ax[ax_i].add_feature(cartopy.feature.COASTLINE)\n",
    "        gl = ax[ax_i].gridlines(draw_labels=True)\n",
    "        gl.xlabel_style['rotation']= 0\n",
    "        gl.xlabel_style['ha']= 'center'\n",
    "        gl.xlabel_style['va']= 'center'\n",
    "        count += 1\n",
    "\n",
    "    # add the colorbar for all plots\n",
    "    print('Adding colorbar...')\n",
    "    plt.tight_layout()\n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, 0.9, 0.04])\n",
    "    #fig.colorbar(color, cax=cbar_ax, label=cbar_label, orientation=\"horizontal\")\n",
    "    plt.colorbar(mapper, cax=cbar_ax, label=cbar_label, orientation=\"horizontal\")\n",
    "    plt.suptitle(title, y=1.02, fontsize='x-large')\n",
    "\n",
    "    #delete subplot if uneven number\n",
    "    if count != (n_rows*n_cols):\n",
    "        if n_cols > 1:\n",
    "            fig.delaxes(ax[n_rows-1,n_cols-1])\n",
    "        else:\n",
    "            fig.delaxes(ax[n])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting - Point Based Coverage\n",
    "- This plotting method uses randomly generated points to determine the number of unique passes over a given location. i.e. it accounts for the duplication of data from overlapping products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_points_in_bounds(filename, number, plot=True): \n",
    "    \"\"\" function to add a fixed number of points randomly in a polygon\n",
    "    \"\"\"  \n",
    "    from shapely.geometry import Point, Polygon\n",
    "    import itertools\n",
    "\n",
    "    #open the spatial AOI\n",
    "    roi_gdf = gpd.read_file(filename)\n",
    "\n",
    "    minx, miny, maxx, maxy = roi_gdf.geometry.bounds.values[0]\n",
    "    xs = np.linspace(minx, maxx, num=number)\n",
    "    ys = np.linspace(miny, maxy, num=number)\n",
    "    #scale number for y\n",
    "    y_number = int(number * (abs(miny-maxy)/abs(minx-maxx)))\n",
    "    ys = np.linspace(miny, maxy, num=y_number)\n",
    "    points = list(itertools.product(xs, ys))\n",
    "    print(len(points))\n",
    "\n",
    "    # x = np.random.uniform( minx, maxx, number )\n",
    "    # y = np.random.uniform( miny, maxy, number )\n",
    "    # points = list(zip(x,y))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['points'] = points\n",
    "    df['points'] = df['points'].apply(Point)\n",
    "    points_gdf = gpd.GeoDataFrame(df, geometry='points', crs=\"EPSG:4326\")\n",
    "    Sjoin = gpd.tools.sjoin(points_gdf, roi_gdf, predicate=\"within\", how='left')\n",
    "    # # Keep points in \"myPoly\"\n",
    "    points_in_poly = Sjoin.intersection(roi_gdf['geometry'].values[0]).to_crs(3031)\n",
    "\n",
    "    # Plot result\n",
    "    if plot:\n",
    "        base = roi_gdf['geometry'].plot(linewidth=1, edgecolor=\"black\")\n",
    "        points_in_poly.plot(ax=base, linewidth=1, color=\"black\", markersize=8)\n",
    "        plt.show()\n",
    "        \n",
    "    return points_in_poly\n",
    "\n",
    "def calculate_valid_intersections(df, points_df, min_revisit_time=10, plot=False):\n",
    "    \n",
    "    # Build spatial index\n",
    "    spatial_index = STRtree(df.geometry)\n",
    "    # Create an empty GeoDataFrame to store the intersections for the current polygon\n",
    "    intersections = []\n",
    "    # Iterate over each polygon in the DataFrame\n",
    "    for p in tqdm(points_df):\n",
    "        # Find potential intersecting polygons using the spatial index\n",
    "        potential_intersections = spatial_index.query(p)\n",
    "        # Check for intersections with potential polygons\n",
    "        for j in potential_intersections:\n",
    "             if p.intersects(df.geometry.iloc[j]):\n",
    "                date = df.start_time.iloc[j]\n",
    "                sza_col = 'sun_zenith_10ra' if df.satellite.iloc[j] in [8,9] else 'sun_zenith'\n",
    "                intersections.append({\n",
    "                    'intersectionpoint':p,\n",
    "                    'intersectionpointstr':str(p),\n",
    "                    'intersectionpoint_x':p.x,\n",
    "                    'intersectionpoint_y':p.y,\n",
    "                    'start_time': df.start_time.iloc[j],\n",
    "                    'cloud_cover': df.cloud_cover.iloc[j],\n",
    "                    'cloud_cover_category': df.cloud_cover_category.iloc[j],\n",
    "                    'start_time': df.start_time.iloc[j],\n",
    "                    'land_cloud_cover': df.land_cloud_cover.iloc[j],\n",
    "                    'scene_cloud_cover': df.scene_cloud_cover.iloc[j],\n",
    "                    'polygon': df.geometry.iloc[j],\n",
    "                    'month_name': df.month_name.iloc[j],\n",
    "                    'year': df.year.iloc[j],\n",
    "                    'satellite' : df.satellite.iloc[j],\n",
    "                    'wrs_path': df.wrs_path.iloc[j],\n",
    "                    'wrs_row': df.wrs_row.iloc[j],\n",
    "                    'sun_zenith_10ra': df[sza_col].iloc[j],\n",
    "                })\n",
    "\n",
    "    #covert to dataframe \n",
    "    intersections = pd.DataFrame.from_dict(intersections)\n",
    "\n",
    "    # sort by point and date aquired\n",
    "    intersections = intersections.sort_values(by=['intersectionpointstr','start_time'])\n",
    "\n",
    "    # calculate the days between observations at a given point\n",
    "    # replace na / first datapoint with placeholder revisit time\n",
    "    placeholder_dt = datetime.timedelta(days=5)\n",
    "    intersections['timebetweenobs'] = (intersections['start_time'] - intersections['start_time'].shift(1)).fillna(placeholder_dt)\n",
    "    \n",
    "    # The first observation for each point does not have another time to compare\n",
    "    intersections[intersections['intersectionpointstr']!=intersections['intersectionpointstr'].shift(1)]['timebetweenobs'] = placeholder_dt\n",
    "    intersections['daysbetweenobs'] = intersections['timebetweenobs'].dt.days.astype(float)\n",
    "    intersections['minutesbetweenobs'] = intersections['timebetweenobs'].dt.total_seconds().astype(int)/60\n",
    "    \n",
    "    # keep only valid revisit times, \n",
    "    # i.e. when a point is measure at least 'min_revisit_time' minutes apart\n",
    "    intersections = intersections[intersections['minutesbetweenobs']>min_revisit_time]\n",
    "    intersections = gpd.GeoDataFrame(intersections, geometry='intersectionpoint', crs=\"EPSG:3031\")\n",
    "\n",
    "    # sort by point and date aquired\n",
    "    intersections = intersections.sort_values(by=['intersectionpointstr','start_time'])\n",
    "\n",
    "    if plot:\n",
    "        heatmap, xedges, yedges = np.histogram2d(\n",
    "        intersections.intersectionpoint_x, \n",
    "        intersections.intersectionpoint_y, \n",
    "        bins=100)\n",
    "        extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "        print(extent)\n",
    "\n",
    "        plt.clf()\n",
    "        plt.title('Heatmap (not freq count)')\n",
    "        plt.imshow(heatmap.T, extent=extent, origin='lower')\n",
    "        plt.colorbar(orientation='horizontal')\n",
    "        plt.show()\n",
    "\n",
    "    return intersections\n",
    "\n",
    "def summarise_intersections(intrsections, group=''):\n",
    "\n",
    "    if group:\n",
    "        groupby = ['intersectionpoint',group]\n",
    "    else:\n",
    "        groupby = ['intersectionpoint']\n",
    "    \n",
    "    intrsection_summary = intrsections.groupby(groupby).agg(\n",
    "        revisit_count=('intersectionpointstr','count'),\n",
    "        mean_revisit_mins=('minutesbetweenobs','mean'),\n",
    "        median_revisit_mins=('minutesbetweenobs','median'),\n",
    "        mean_cloudcover=('cloud_cover','mean'),\n",
    "        median_cloudcover=('cloud_cover','median'),\n",
    "        mean_sza=('sun_zenith_10ra','mean'),\n",
    "        min_sza=('sun_zenith_10ra','min'),\n",
    "        max_sza=('sun_zenith_10ra','max'),\n",
    "    ).reset_index()\n",
    "    \n",
    "    return intrsection_summary\n",
    "\n",
    "def plot_intersection_frequency(intrsections, plot_var, title='', cbar_label='',shape=(1000,1000), cmap='viridis', force_max=''):\n",
    "    \n",
    "    # summarise the intersections\n",
    "    intrsection_summary = summarise_intersections(intrsections)\n",
    "    \n",
    "    crs = ccrs.SouthPolarStereo()\n",
    "    bounds = crs.boundary.bounds\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "\n",
    "    freq_raster = np.zeros(shape)\n",
    "    for i,row in intrsection_summary.iterrows():\n",
    "        point = row.intersectionpoint\n",
    "        count = row[plot_var]\n",
    "        new_rast = rasterize([(point, count)], out_shape=shape, transform=transform)\n",
    "        # replace the value where higher - i.e. get max value per pixel\n",
    "        r,c = np.where(new_rast>freq_raster)\n",
    "        freq_raster[(r,c)] = new_rast[(r,c)]\n",
    "\n",
    "    # plot the raster\n",
    "    freq_raster[freq_raster==0] = np.nan\n",
    "    if force_max:\n",
    "        freq_raster[freq_raster>force_max] = force_max\n",
    "    raster = freq_raster #cc_raster if cloud else freq_raster\n",
    "\n",
    "    crs = ccrs.SouthPolarStereo()\n",
    "    shape = 1000, 1000\n",
    "    bounds = crs.boundary.bounds\n",
    "    east, west, south, north = -180, 180, -90, -50\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = [10,8]\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.set_extent((east, west, south, north+1), ccrs.PlateCarree())\n",
    "    ax.add_feature(cartopy.feature.LAND)\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    color = ax.imshow(raster, origin=\"upper\", extent=(bounds[0], bounds[2], bounds[1], bounds[3]), transform=ccrs.SouthPolarStereo(), cmap=cmap)\n",
    "    ax.add_feature(cartopy.feature.COASTLINE)\n",
    "    cbar_max = int(raster[raster>-1].max())\n",
    "    plt.colorbar(color, ticks=np.linspace(0, cbar_max, 10, dtype=int), label=cbar_label)\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiple_intersection_frequency(intrsections, plot_var, group, sort_vals='', n_cols=2, title='', cbar_label='',shape=(1000,1000)):\n",
    "    \n",
    "    # summarise the intersections\n",
    "    intrsection_summary = summarise_intersections(intrsections, group=group)\n",
    "    \n",
    "    crs = ccrs.SouthPolarStereo()\n",
    "    bounds = crs.boundary.bounds\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "\n",
    "     # calculate the size of the figure\n",
    "    n = intrsection_summary[group].nunique()\n",
    "    n_rows = math.ceil(n/n_cols)\n",
    "\n",
    "    # using the variable axs for multiple Axes\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols,\n",
    "                        subplot_kw={'projection': ccrs.SouthPolarStereo()},\n",
    "                        figsize=(n_cols*5,n_rows*4.5))\n",
    "    \n",
    "    # product count by group to get max and min for colorbar\n",
    "    minima = intrsection_summary[plot_var].min()\n",
    "    maxima = intrsection_summary[plot_var].max()\n",
    "\n",
    "    east, west, south, north = -180, 180, -90, -50\n",
    "    \n",
    "    # colorbar\n",
    "    import matplotlib.cm as cm\n",
    "    norm = matplotlib.colors.Normalize(vmin=minima, vmax=maxima, clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap=cm.viridis)\n",
    "    count = 0\n",
    "\n",
    "    groups = intrsections[group].unique()\n",
    "    if 'January' in groups:\n",
    "        print('Months')\n",
    "        groups = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "    else:\n",
    "        print('Years')\n",
    "        groups = sorted(groups)\n",
    "    print(groups)\n",
    "    for g in tqdm(groups):\n",
    "        g_intrsection_summary = intrsection_summary[intrsection_summary[group]==g]\n",
    "        raster = np.zeros(shape)\n",
    "        for i,row in g_intrsection_summary.iterrows():\n",
    "            \n",
    "            # data\n",
    "            point = row.intersectionpoint\n",
    "            plot_val = row[plot_var]\n",
    "            new_rast = rasterize([(point, plot_val)], out_shape=shape, transform=transform)\n",
    "            \n",
    "            # replace the value where higher - i.e. get max value per pixel\n",
    "            r_,c_ = np.where(new_rast>raster)\n",
    "            raster[(r_,c_)] = new_rast[(r_,c_)]\n",
    "\n",
    "        raster[raster==0] = np.nan\n",
    "        r = math.floor((count)/n_cols)\n",
    "        c = count % n_cols\n",
    "        ax_i = (r,c) if ((n_cols > 1) and (n_rows>1)) else count # only a single index needed if no cols\n",
    "        # get product data for each catagory\n",
    "        #n_products = g_intrsection_summary\n",
    "        ax[ax_i].set_extent((east, west, south, north), ccrs.PlateCarree())\n",
    "        ax[ax_i].add_feature(cartopy.feature.LAND)\n",
    "        ax[ax_i].add_feature(cartopy.feature.OCEAN)\n",
    "        ax[ax_i].title.set_text(f'{g}')\n",
    "        color = ax[ax_i].imshow(raster, \n",
    "                                origin=\"upper\", \n",
    "                                extent=(bounds[0], bounds[2], bounds[1], bounds[3]), \n",
    "                                transform=ccrs.SouthPolarStereo(),\n",
    "                                vmin=minima,\n",
    "                                vmax=maxima\n",
    "                                )\n",
    "        ax[ax_i].add_feature(cartopy.feature.COASTLINE)\n",
    "        gl = ax[ax_i].gridlines(draw_labels=True)\n",
    "        gl.xlabel_style['rotation']= 0\n",
    "        gl.xlabel_style['ha']= 'center'\n",
    "        gl.xlabel_style['va']= 'center'\n",
    "        count += 1\n",
    "\n",
    "    # add the colorbar for all plots\n",
    "    plt.tight_layout()\n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, 0.9, 0.04])\n",
    "    plt.colorbar(mapper, cax=cbar_ax, label=cbar_label, orientation=\"horizontal\")\n",
    "    plt.suptitle(title, y=1.03, fontsize='x-large')\n",
    "\n",
    "    #delete subplot if uneven number\n",
    "    if count != (n_rows*n_cols):\n",
    "        if n_cols > 1:\n",
    "            fig.delaxes(ax[n_rows-1,n_cols-1])\n",
    "        else:\n",
    "            fig.delaxes(ax[n])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a set of points for intersection plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_POINTS = 500\n",
    "MAX_DATE = datetime.datetime.strptime('16/06/23', '%d/%m/%y')\n",
    "points_in_roi = generate_points_in_bounds(roi_shape, N_POINTS, plot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat datasets\n",
    "\n",
    "| Dataset Name | Dataset ID |\n",
    "|---|---|\n",
    "| Landsat 5 TM Collection 2 Level 1 | landsat_tm_c2_l1 |\n",
    "| Landsat 5 TM Collection 2 Level 2 | landsat_tm_c2_l2 |\n",
    "| Landsat 7 ETM+ Collection 2 Level 1 | landsat_etm_c2_l1 |\n",
    "| Landsat 7 ETM+ Collection 2 Level 2 | landsat_etm_c2_l2 |\n",
    "| Landsat 8 Collection 2 Level 1 | landsat_ot_c2_l1 |\n",
    "| Landsat 8 Collection 2 Level 2 | landsat_ot_c2_l2 |\n",
    "| Landsat 9 Collection 2 Level 1 | landsat_ot_c2_l1 |\n",
    "| Landsat 9 Collection 2 Level 2 | landsat_ot_c2_l2 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat 8/9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the scenes\n",
    "df = None\n",
    "lsat_filename = \"metadata/landsat_ot_c2_l1_-50N_products.json\"\n",
    "#lsat_filename = \"metadata/landsat_ot_c2_l2_-50N_products.json\"\n",
    "level = 'Level 1' if 'l1' in lsat_filename else 'Level 2'\n",
    "df = pd.read_json(lsat_filename, orient='index')\n",
    "df = preprocess_landsat(df, max_date=MAX_DATE)\n",
    "df = filter_results_with_geojson(df, roi_shape, plot=True)\n",
    "plot_geometries_on_map(df)\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['start_time'].min(), df['start_time'].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Landsat 8/9 {level} - Weekly Products' \n",
    "plot_timeseries_products(df, title=title,stack_col='sat_id', date_col='start_time',count_freq='7D', plot_freq='1M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year\n",
    "df_sum = df.groupby(['year']).agg(\n",
    "    product_count=('landsat_product_id','count'),\n",
    "    size_mb=('size_compressed_mb','sum'),\n",
    "    ).reset_index().sort_values('year')\n",
    "df_sum['size_gb'] = (df_sum['size_mb']/1000).astype(int)\n",
    "df_sum['size_tb'] = (df_sum['size_gb']/1000).astype(float).round(2)\n",
    "df_sum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year_month\n",
    "df_sum = df.groupby(['year','month','month_name']).agg(\n",
    "    product_count=('landsat_product_id','count'),\n",
    "    size_mb=('size_compressed_mb','sum'),\n",
    "    ).reset_index().sort_values('month')\n",
    "df_sum['size_gb'] = (df_sum['size_mb']/1000).astype(int)\n",
    "df_sum['size_tb'] = (df_sum['size_gb']/1000).astype(int)\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day night\n",
    "print(df['day-night_indicator'].value_counts())\n",
    "\n",
    "# sat counts\n",
    "print('\\n')\n",
    "print(df['satellite'].value_counts())\n",
    "\n",
    "# cloud cover cats\n",
    "print(df['cloud_cover_category'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sun zenith\n",
    "df['centroid'] = df['geometry_4326'].apply(lambda x : x.centroid)\n",
    "df['centroid_x'] = df['centroid'].apply(lambda x : x.x)\n",
    "df['centroid_y'] = df['centroid'].apply(lambda x : x.y)\n",
    "\n",
    "bins = [-90, -85, -80, -75, -70, -65, -60, -55, -50, -45]\n",
    "labels = ['85-90', '80-85', '75-80', '70-75', '65-70', '60-65', '55-60', '50-55', 'less than 50']\n",
    "df['lon_category'] = pd.cut(x = df['centroid_y'], bins = bins, labels = labels, include_lowest = True)\n",
    "\n",
    "df['sun_zenith_over_70'] = df['sun_zenith_10ra'] > 70\n",
    "df['sun_zenith_over_76'] = df['sun_zenith_10ra'] > 76\n",
    "df['sun_zenith_over_88'] = df['sun_zenith_10ra'] > 88\n",
    "\n",
    "zenith_by_lat = df[df['year']==2022].groupby('lon_category').agg(\n",
    "    count=('sun_zenith_over_76','count'),\n",
    "    sun_zenith_over_70=('sun_zenith_over_70','sum'),\n",
    "    sun_zenith_over_76=('sun_zenith_over_76','sum'),\n",
    "    sun_zenith_over_88=('sun_zenith_over_88','sum'),\n",
    ").reset_index()\n",
    "zenith_by_lat\n",
    "\n",
    "#print(df['sun_zenith_over_76'].count(), df['sun_zenith_over_76'].sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Product Count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Landsat 8/9 {level} - Count of Products by Path/Row tile (2022)'\n",
    "plot_mgrs_product_count(df[(df['year']==2022) & (df['day-night_indicator'] == 'DAY')], title=title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Night (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Landsat 8/9 {level} - Count of NIGHTTIME Products by Path/Row tile (2022)'\n",
    "plot_mgrs_product_count(df[(df['year']==2022) & (df['day-night_indicator'] == 'NIGHT')], title=title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tiles = gpd.read_file('WRS2_descending_0_daytime/WRS2_descending.shp') \n",
    "# df_tiles\n",
    "title = f'Landsat 8/9 {level} - Count of Products by Path/Row tile (2022)'\n",
    "#plot_mgrs_product_count(df, title=title)\n",
    "plot_multiple_product_count(df[(df['year']==2022) & (df['day-night_indicator'] == 'DAY')], 'month_name', title='', n_cols=3, cbar_label='Count of Products')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Landsat 8/9 {level} - Revisit Count by Year'\n",
    "#plot_mgrs_product_count(df, title=title)\n",
    "plot_multiple_product_count(df[(df['day-night_indicator'] == 'DAY')], 'year', title='', n_cols=4, cbar_label='Revisit Count')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Cover Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tiles = gpd.read_file('WRS2_descending_0_daytime/WRS2_descending.shp') \n",
    "# df_tiles\n",
    "title = f'Landsat 8/9 {level} - Count of Products by Cloud Cover Category (2022)'\n",
    "#plot_mgrs_product_count(df, title=title)\n",
    "plot_multiple_product_count(df[(df['day-night_indicator'] == 'DAY') & (df['year']==2022) ], 'cloud_cover_category', title=title, n_cols=3, cbar_label='Count of Products')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual (All years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tiles = gpd.read_file('WRS2_descending_0_daytime/WRS2_descending.shp') \n",
    "# df_tiles\n",
    "title = f'Landsat 8/9 {level} - Annual Count of Products by Path/Row tile'\n",
    "#plot_mgrs_product_count(df, title=title)\n",
    "plot_multiple_product_count(df[(df['day-night_indicator'] == 'DAY')], 'year', title=title, n_cols=4, cbar_label='Count of Products')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisit (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title = f'Landsat 8/9 {level} Revisit Frequency (2022)'\n",
    "cbar_label = 'Revisit Count'\n",
    "intersections = calculate_valid_intersections(df[(df['year']==2022) & (df['day-night_indicator'] == 'DAY')], points_df=points_in_roi)\n",
    "plot_intersection_frequency(intersections, plot_var='revisit_count', title=title, cbar_label=cbar_label, shape=(1000,1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Landsat 8/9 {level} Revisit Frequency by Month (2022)'\n",
    "cbar_label = 'Revisit Count'\n",
    "#intersections = calculate_valid_intersections(df[(df['year']==2022) & (df['day-night_indicator'] == 'DAY')], points_df=points_in_roi)\n",
    "plot_multiple_intersection_frequency(intersections, plot_var='revisit_count', group='month_name', n_cols=4, title=title, cbar_label=cbar_label, shape=(1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### SZA < 76\n",
    "# # appriximate cloudcover with overlapping products\n",
    "# title = f'Landsat 8/9 {level} Revisit Frequency SZA < 76 (2022)'\n",
    "# cbar_label = 'Revisit Count'\n",
    "# intersections = calculate_valid_intersections(\n",
    "#     df[(df['year']==2022) & (df['day-night_indicator'] == 'DAY') & (df['sun_zenith_10ra'] < 76)]\n",
    "#     , points_df=points_in_roi)\n",
    "# plot_intersection_frequency(intersections, plot_var='revisit_count', title=title, cbar_label=cbar_label, shape=(220,220))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Cover (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Landsat 8/9 {level} Approximate Cloud Cover (2022)'\n",
    "cbar_label = 'Mean Observation Cloud Cover (%)'\n",
    "#intersections = calculate_valid_intersections(df[df['year']==2022], points_df=points_in_roi)\n",
    "plot_intersection_frequency(intersections, plot_var='mean_cloudcover', title=title, cbar_label=cbar_label, shape=(1000,1000), cmap='plasma')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Cover by Category (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Landsat 8/9 {level} - Count of Observations by Cloud Cover Category (2022)'\n",
    "cbar_label = 'Revisit Count'\n",
    "#intersections = calculate_valid_intersections(df[df['year']==2022], points_df=points_in_roi)\n",
    "plot_multiple_intersection_frequency(intersections, plot_var='revisit_count', group='cloud_cover_category', n_cols=3, title=title, cbar_label=cbar_label, shape=(1000,1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sun Zenith Angle (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Landsat 8/9 {level} - Mean Sun Zenith Angle (2022)'\n",
    "cbar_label = 'Mean Sun Zenith Angle'\n",
    "#intersections = calculate_valid_intersections(df[df['year']==2022], points_df=points_in_roi)\n",
    "plot_intersection_frequency(intersections, plot_var='mean_sza', title=title, cbar_label=cbar_label, shape=(1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Landsat 8/9 {level} - Minimum Sun Zenith Angle (2022)'\n",
    "cbar_label = 'Minimum Sun Zenith Angle'\n",
    "#intersections = calculate_valid_intersections(df[df['year']==2022], points_df=points_in_roi)\n",
    "plot_intersection_frequency(intersections, plot_var='min_sza', title=title, cbar_label=cbar_label, shape=(1000,1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisit 2022 (monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Landsat 8/9 {level} - Revisit Frequency (2022)'\n",
    "cbar_label = 'Revisit Count'\n",
    "#intersections = calculate_valid_intersections(df[df['year']==2022], points_df=points_in_roi)\n",
    "plot_multiple_intersection_frequency(intersections, plot_var='revisit_count', group='month_name', n_cols=4, title=title, cbar_label=cbar_label, shape=(1000,1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra stuff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_tier'] = df['landsat_product_id'].apply(lambda x : x.split('_')[-1])\n",
    "df.groupby('product_tier')['landsat_product_id'].count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sun Zenith Azumith (SZA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['sun_zenith_10ra'] = 90 - df['sun_elevation_l0ra'] \n",
    "#df[['sun_elevation_l0ra', 'sun_azimuth_l0ra','sun_zenith_10ra','start_time']]\n",
    "title = f'Landsat 8/9 {level} Distribution of Product Sun Zenith Angles (2013-03 to 2023-06)' #2013-03-10 22:59:32 2023-06-15 23:28:39\n",
    "ax = df[(df['day-night_indicator']=='DAY') \n",
    "        & (df['year'])]['sun_zenith_10ra'].plot(kind='hist', title=title, bins=20, figsize=(10,5))\n",
    "ax.axvline(x=76, color='red', linestyle='--')\n",
    "ax.set_xlabel('Sun Zenith Angle (SZA)')\n",
    "ax.set_ylabel('Count of Products')\n",
    "#ax.annotate('Maximum SZA for Producing\\nLevel-2 Products (76°)', (77, 14_000), color='red')\n",
    "ax.annotate('76°', (77, 14_000), color='red')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['day-night_indicator'].value_counts())\n",
    "plot_geometries_on_map(df[df['day-night_indicator']=='NIGHT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    (df['wrs_path']==4)\n",
    "    & (df['wrs_row'].isin([110,111]))\n",
    "    ].plot(alpha=0.1)\n",
    "df[\n",
    "    (df['wrs_path']==4)\n",
    "    & (df['wrs_row']==110)\n",
    "    ].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Accuracy (Heard & Macquarie Islands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for Landsat TM scenes\n",
    "start_date='2013-01-01'\n",
    "end_date='2023-06-15'\n",
    "\n",
    "#Heard + mcdonald\n",
    "loc = 'Heard and McDonald Islands'\n",
    "bbox = (72,-54,75,-52)\n",
    "extent = (72, 75, -54, -52)\n",
    "\n",
    "# Macquarie\n",
    "# loc = 'Macquarie Island'\n",
    "# bbox = (157,-56,160,-53)\n",
    "# extent = (157, 160, -56, -53)\n",
    "\n",
    "scenes = api.search(\n",
    "    dataset='landsat_ot_c2_l2',\n",
    "    bbox=bbox,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    max_results=max_results,\n",
    ")\n",
    "\n",
    "# Create a DataFrame from the scenes\n",
    "df = pd.DataFrame(scenes)\n",
    "df = gpd.GeoDataFrame(df, geometry='spatial_coverage', crs=\"EPSG:4326\")\n",
    "print(df.shape)\n",
    "plot_geometries_on_map(df, extent=extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select which satellite\n",
    "sat = 8 #landsat 8 or 9 \n",
    "color = '#1f77b4' if (sat==8) else 'green'\n",
    "alpha = 1 if ('Heard' in loc) else 1\n",
    "\n",
    "plot_geometries_on_map(df[~df['geometric_rmse_model'].isna()], extent=extent)\n",
    "df_control = df[\n",
    "    (df.ground_control_points_model>0)\n",
    "    & (df.satellite==sat)]\n",
    "\n",
    "f, ax =  plt.subplots(1, figsize=(8,6))\n",
    "ax.hist(df_control.geometric_rmse_model.values, bins=20, color=color, alpha=alpha)\n",
    "n = len(df_control)\n",
    "mn,mx = df_control.acquisition_date.min().date(), df_control.acquisition_date.max().date()\n",
    "ax.set_title(f'Landsat-{sat} Geometric Error - {loc}\\n{mn} to {mx} ({n} samples)')\n",
    "ax.set_xlabel('Geometric RMSE (metres)')\n",
    "ax.set_ylabel('Number of Samples')\n",
    "plt.savefig(f'data/landsat{sat}_{loc}_{mn}_{mx}_GCP_acc.png')\n",
    "plt.show()\n",
    "\n",
    "df_control = df_control[\n",
    "    ['entity_id',\n",
    "    'cloud_cover',\n",
    "    'acquisition_date',\n",
    "    'ground_control_points_model',\n",
    "    'ground_control_points_version',\n",
    "    'geometric_rmse_model_x',\n",
    "    'geometric_rmse_model_y',\n",
    "    'geometric_rmse_model',]].sort_values('acquisition_date')\n",
    "\n",
    "df_control.to_csv(f'data/landsat{sat}_{loc}_{mn}_{mx}_GPC_acc.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control[['satellite']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the scenes\n",
    "lsat_filename = \"metadata/landsat_etm_c2_l1_-50N_products.json\"\n",
    "# lsat_filename = \"metadata/landsat_etm_c2_l2_-50N_products.json\"\n",
    "level = 'Level 1' if 'l1' in lsat_filename else 'Level 2'\n",
    "df = pd.read_json(lsat_filename, orient='index')\n",
    "df = preprocess_landsat(df, max_date=MAX_DATE)\n",
    "df = filter_results_with_geojson(df, roi_shape, plot=True)\n",
    "plot_geometries_on_map(df)\n",
    "print(list(df))\n",
    "df.geometry.bounds.miny.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Landsat 7 {level} - Weekly Products' \n",
    "plot_timeseries_products(df, title=title,stack_col='sat_id', date_col='start_time',count_freq='7D', plot_freq='1M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year\n",
    "df_sum = df.groupby(['year']).agg(\n",
    "    product_count=('landsat_product_id','count'),\n",
    "    size_mb=('size_compressed_mb','sum'),\n",
    "    ).reset_index().sort_values('year')\n",
    "df_sum['size_gb'] = (df_sum['size_mb']/1000).astype(int)\n",
    "df_sum['size_tb'] = (df_sum['size_gb']/1000).astype(float).round(2)\n",
    "df_sum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sun zenith\n",
    "df['centroid'] = df['geometry_4326'].apply(lambda x : x.centroid)\n",
    "df['centroid_x'] = df['centroid'].apply(lambda x : x.x)\n",
    "df['centroid_y'] = df['centroid'].apply(lambda x : x.y)\n",
    "\n",
    "bins = [-90, -85, -80, -75, -70, -65, -60, -55, -50, -45]\n",
    "labels = ['85-90', '80-85', '75-80', '70-75', '65-70', '60-65', '55-60', '50-55', 'less than 50']\n",
    "df['lon_category'] = pd.cut(x = df['centroid_y'], bins = bins, labels = labels, include_lowest = True)\n",
    "\n",
    "df['sun_zenith_over_76'] = df['sun_zenith'] > 76\n",
    "df['sun_zenith_over_88'] = df['sun_zenith'] > 88\n",
    "\n",
    "zenith_by_lat = df[df['year'] ==2022].groupby('lon_category').agg(\n",
    "    count=('sun_zenith_over_76','count'),\n",
    "    sun_zenith_over_76=('sun_zenith_over_76','sum'),\n",
    "    sun_zenith_over_88=('sun_zenith_over_88','sum'),\n",
    ").reset_index()\n",
    "zenith_by_lat\n",
    "\n",
    "print(df['sun_zenith_over_76'].count(), df['sun_zenith_over_76'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE - must be level 1\n",
    "title = f'Landsat 7 {level} - Distribution of Product Sun Zenith Angles'\n",
    "ax = df[(df['day-night_indicator']=='DAY')]['sun_zenith'].plot(kind='hist', title=title, bins=20, figsize=(10,5))\n",
    "ax.axvline(x=76, color='red', linestyle='--')\n",
    "ax.set_xlabel('Sun Zenith Angle (SZA)')\n",
    "ax.set_ylabel('Count of Products')\n",
    "ax.annotate('Maximum SZA for Producing\\nLevel-2 Products (76°)', (77, 4_000), color='red')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual (All years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Landsat 7 Level 1 - Count of Products by Path/Row Tile ()'\n",
    "#plot_mgrs_product_count(df[(df['year']==2011)], title=title)\n",
    "plot_multiple_product_count(df[df['year']<2015], 'year', title=title, n_cols=6, cbar_label='Count of Products')\n",
    "#df['year'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisit (2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Landsat 7 Level 1 Revisit Frequency (2011)' # - ADJUSTED SCALE'\n",
    "cbar_label = 'Revisit Count'\n",
    "intersections = calculate_valid_intersections(df[(df['year']==2011) & (df['day-night_indicator'] == 'DAY')], points_df=points_in_roi)\n",
    "plot_intersection_frequency(intersections, plot_var='revisit_count', title=title, cbar_label=cbar_label, shape=(1000,1000))#, force_max=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly (2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tiles = gpd.read_file('WRS2_descending_0_daytime/WRS2_descending.shp') \n",
    "# df_tiles\n",
    "title = 'Landsat 7 Level 1 - Count of Products by Path/Row tile (2011)'\n",
    "#plot_mgrs_product_count(df, title=title)\n",
    "plot_multiple_product_count(df[(df['year']==2011) & (df['day-night_indicator'] == 'DAY')].sort_values('month')\n",
    "                            , 'month_name', title='', n_cols=3, cbar_label='Count of Products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Landsat 7 Level 1 Revisit Frequency by month (2011)'\n",
    "cbar_label = 'Revisit Count'\n",
    "#intersections = calculate_valid_intersections(df[(df['year']==2011) & (df['day-night_indicator'] == 'DAY')], points_df=points_in_roi)\n",
    "plot_multiple_intersection_frequency(intersections, plot_var='revisit_count', group='month_name', n_cols=4, title=title, cbar_label=cbar_label, shape=(1000,1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the scenes\n",
    "lsat_filename = \"metadata/landsat_tm_c2_l1_-50N_products.json\"\n",
    "#lsat_filename = \"metadata/landsat_tm_c2_l2_-50N_products.json\"\n",
    "level = 'Level 1' if 'l1' in lsat_filename else 'Level 2'\n",
    "df = pd.read_json(lsat_filename, orient='index')\n",
    "print(df['satellite'].value_counts())\n",
    "df = df[df['satellite'].isin(['LANDSAT_4',4])] # exclude lsat 4\n",
    "df = preprocess_landsat(df)\n",
    "df = filter_results_with_geojson(df, roi_shape, plot=True)\n",
    "plot_geometries_on_map(df)\n",
    "print(list(df))\n",
    "df.geometry.bounds.miny.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_time'].min(), df['start_time'].max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Landsat 4/5 {level} - Weekly Products' \n",
    "plot_timeseries_products(df, title=title,stack_col='sat_id', date_col='start_time',count_freq='7D', plot_freq='2M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year\n",
    "df_sum = df.groupby(['year']).agg(\n",
    "    product_count=('landsat_product_id','count'),\n",
    "    size_mb=('size_compressed_mb','sum'),\n",
    "    ).reset_index().sort_values('year')\n",
    "df_sum['size_gb'] = (df_sum['size_mb']/1000).astype(int)\n",
    "df_sum['size_tb'] = (df_sum['size_gb']/1000).astype(float).round(2)\n",
    "df_sum['avg_size_mb'] = df_sum['size_mb']/df_sum['product_count']\n",
    "df_sum.loc['tot'] = df_sum.sum()\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Landsat 5 {level} - Count of Products by Path/Row Tile'\n",
    "#plot_mgrs_product_count(df[(df['year']==2011)], title=title)\n",
    "plot_multiple_product_count(df, 'year', title=title, n_cols=5, cbar_label='Count of Products')\n",
    "#df['year'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisit 1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Landsat 5 {level} Revisit Frequency (1991)'\n",
    "cbar_label = 'Revisit Count'\n",
    "intersections = calculate_valid_intersections(df[(df['year']==1991) & (df['day-night_indicator'] == 'DAY')], points_df=points_in_roi)\n",
    "plot_intersection_frequency(intersections, plot_var='revisit_count', title=title, cbar_label=cbar_label, shape=(1000,1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filesize\n",
    "\n",
    "https://www.usgs.gov/faqs/what-are-landsat-collection-1-level-1-data-product-file-sizes\n",
    "\n",
    "| Sensor | Compressed file | Uncompressed file |\n",
    "|---|---|---|\n",
    "| Landsat 8 OLI/TIRS | 919 MB | 1.61 GB |\n",
    "| Landsat 7 ETM+ | 235 MB | 785 MB |\n",
    "| Landsat 4-5 TM | 150 MB | 500 MB |\n",
    "| Landsat 1-5 MSS | 20 MB | 75 MB |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
