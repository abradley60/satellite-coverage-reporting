{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69bf4b94-bc0e-48c4-8e43-c574bd71f87a",
   "metadata": {},
   "source": [
    "# Plotting Sentinel Satellite data Frequency And Summary Statistics Over Antarctica"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50619391",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Sentinel Data is Downloaded using the download_metadata.ipynb notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19227f4-2138-4031-9bec-491c7511a664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import shapely.wkt\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib\n",
    "from shapely.strtree import STRtree\n",
    "import datetime\n",
    "\n",
    "from fiona.transform import transform_geom\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely.ops import polygonize_full, unary_union\n",
    "\n",
    "import shared_functions as sf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a3dc10f",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09386ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DATE = datetime.datetime.strptime(\n",
    "    '16/06/23', '%d/%m/%y')\n",
    "N_POINTS = 500 # number of spatial points to identify intersection of passes\n",
    "roi_shape = 'shapefiles/50south_excl_argentina_falkand_mid.geojson'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "399b6a1b",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bebbb3a",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata(df, date_col='datatakesensingstart', max_date='', CRS=3031):\n",
    "    \n",
    "    df['geometry'] = df['footprint'].apply(lambda x : shapely.wkt.loads(x))\n",
    "    df['geometry_4326'] = df['geometry'].copy()\n",
    "    df[date_col] = df[date_col].apply(lambda x : str(x).split('.')[0])\n",
    "    df[date_col] = pd.to_datetime(df[date_col], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df['month'] = df[date_col].dt.month\n",
    "    df['month_name'] = df[date_col].dt.month_name()\n",
    "    df['year'] = df[date_col].dt.year\n",
    "    df['sat_id'] = df['identifier'].apply(lambda x : x.split('_')[0])\n",
    "    if max_date:\n",
    "        df = df[df[date_col] < max_date]\n",
    "    df = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "    df = df.to_crs(CRS)\n",
    "    return df\n",
    "\n",
    "def filter_results_with_geojson(df, filename, plot=False):\n",
    "\n",
    "    gdf_inclusion = gpd.read_file(filename).set_crs(4326)\n",
    "    l1 = len(df)\n",
    "    df = df[df['geometry_4326'].apply(lambda x : x.intersects(gdf_inclusion.geometry.values[0]))]\n",
    "    print(f'{l1 - len(df)} products have been removed')\n",
    "\n",
    "    if plot:\n",
    "        plt.rcParams[\"figure.figsize\"] = [10,8]\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree(), title='Product Search Area - 50deg south excl. South America and Falkland Islands')\n",
    "        ax.add_feature(cartopy.feature.LAND)\n",
    "        ax.add_feature(cartopy.feature.OCEAN)\n",
    "        ax.add_geometries(gdf_inclusion.geometry, crs=ccrs.PlateCarree(), alpha=0.7)\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_results_footprint_map(df, title=''):\n",
    "    # plot the the product geometries on a map\n",
    "    east, west, south, north = -180, 180, -90, -50\n",
    "    plt.rcParams[\"figure.figsize\"] = [10,8]\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.set_extent((east, west, south, north+1), ccrs.PlateCarree())\n",
    "    ax.add_feature(cartopy.feature.LAND)\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    ax.add_geometries(df.geometry, crs=ccrs.SouthPolarStereo(), alpha=0.3)\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    plt.show()\n",
    "\n",
    "def wkt_to_geojson(wkt, filename):\n",
    "    t = shapely.wkt.loads(wkt)\n",
    "    t = shapely.to_geojson(t)\n",
    "    gdf = gpd.read_file(t, driver='GeoJSON')\n",
    "    gdf.set_crs(crs='EPSG:4326')\n",
    "    gdf.to_file(filename, driver='GeoJSON')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ad279aa",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc854bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_s1(df_s1):\n",
    "    # read in dataframe S1\n",
    "    print(f'Summarising Sentinel-1 ({df_s1.ingestiondate.min()} to {df_s1.ingestiondate.max()})')\n",
    "    df_s1['sizeGB'] = df_s1['size'].apply(lambda x : \n",
    "                                            float(x.split(' ')[0]) if 'GB' in x else\n",
    "                                            float(x.split(' ')[0])/1000 if 'MB' in x else \n",
    "                                            float(x.split(' ')[0])/1E6 if 'KB' in x else\n",
    "                                            float(x.split(' ')[0])*1000 if 'TB' in x else\n",
    "                                            '?')\n",
    "    \n",
    "    df_s1['sizeTB'] = df_s1['sizeGB']/1000\n",
    "    # summary of products\n",
    "    df_s1_sum = df_s1.groupby(['sensoroperationalmode','polarisationmode']).aggregate(\n",
    "        start = ('ingestiondate','min'),\n",
    "        end = ('ingestiondate','max'),\n",
    "        product_count=('sizeGB','count'),\n",
    "        size_GB=('sizeGB','sum'),\n",
    "        size_TB=('sizeTB','sum'),\n",
    "    ).reset_index()\n",
    "    df_s1_sum['start'] = pd.to_datetime(df_s1_sum['start']).dt.date\n",
    "    df_s1_sum['end'] = pd.to_datetime(df_s1_sum['end']).dt.date\n",
    "    df_s1_sum.loc[\"Total\"] = df_s1_sum.sum(numeric_only=True)\n",
    "    df_s1_sum = df_s1_sum.fillna('').round(1)\n",
    "    df_s1_sum['product_count'] = df_s1_sum['product_count'].astype(int)\n",
    "    return df_s1_sum\n",
    "\n",
    "def year_month_product_summary(df):\n",
    "\n",
    "    # read in dataframe S2\n",
    "    print(f'Summarising ({df.ingestiondate.min()} to {df.ingestiondate.max()})')\n",
    "    df[['ingestiondate','year','month','month_name','platformname','producttype','size']]\n",
    "    df['sizeGB'] = df['size'].apply(lambda x : \n",
    "                                            float(x.split(' ')[0]) if 'GB' in x else\n",
    "                                            float(x.split(' ')[0])/1000 if 'MB' in x else \n",
    "                                            float(x.split(' ')[0])/1E6 if 'KB' in x else\n",
    "                                            float(x.split(' ')[0])*1000 if 'TB' in x else\n",
    "                                            '?')\n",
    "    df['sizeMB'] = df['sizeGB']*1000\n",
    "    df['sizeTB'] = df['sizeGB']/1000\n",
    "\n",
    "    # monthly summary\n",
    "    df_m_sum = df.groupby(['year','month']).aggregate(\n",
    "        month_name=('month_name','first'),\n",
    "        product_count=('sizeGB','count'),\n",
    "        size_GB=('sizeGB','sum'),\n",
    "        size_TB=('sizeTB','sum'),\n",
    "    ).reset_index().sort_values(['year','month'])\n",
    "\n",
    "    df_m_sum.loc[\"Total\"] = df_m_sum.sum(numeric_only=True).drop(['month'])\n",
    "    df_m_sum = df_m_sum.fillna('').round(1)\n",
    "    df_m_sum['product_count'] = df_m_sum['product_count'].astype(int)\n",
    "\n",
    "    # Annual summary\n",
    "    df_y_sum = df.groupby(['year']).aggregate(\n",
    "        product_count=('sizeGB','count'),\n",
    "        size_MB=('sizeMB','sum'),\n",
    "        size_GB=('sizeGB','sum'),\n",
    "        size_TB=('sizeTB','sum'),\n",
    "    ).reset_index().sort_values(['year'])\n",
    "\n",
    "    df_y_sum.loc[\"Total\"] = df_y_sum.sum(numeric_only=True)\n",
    "    df_y_sum = df_y_sum.fillna('').round(1)\n",
    "    df_y_sum['product_count'] = df_y_sum['product_count'].astype(int)\n",
    "    df_y_sum.loc['Total','year'] = ''\n",
    "    df_y_sum['avg_size_MB'] = df_y_sum['size_MB']/df_y_sum['product_count']\n",
    "\n",
    "    return df_m_sum, df_y_sum\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b73ff20",
   "metadata": {},
   "source": [
    "## Plotting - Timeseries Product Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_timeseries_products(df, title='',stack_col='sat_id', date_col='beginposition',count_freq='7D', plot_freq='1M'):\n",
    "    import seaborn as sns\n",
    "    sns.set_theme()\n",
    "    sns.set(rc={'figure.figsize':(10,2)})\n",
    "    df['round_time'] = df[date_col].dt.round(count_freq)\n",
    "    c = df[['round_time',stack_col,'filename']].groupby(['round_time',stack_col]).count().reset_index()\n",
    "    c = c.pivot(index='round_time', columns=stack_col, values='filename').fillna(0)\n",
    "    c = c.resample(plot_freq).max()\n",
    "    ax = c.plot(kind='bar', stacked=True, width=1)\n",
    "    import matplotlib.ticker as ticker\n",
    "    ticklabels = ['']\n",
    "    for i in range(1,len(c.index)):\n",
    "        ticklabels.append('') if c.index[i].year == c.index[i-1].year else ticklabels.append(c.index[i].year)\n",
    "    ax.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels))\n",
    "    ax.set_xlabel('')\n",
    "    plt.xticks(rotation = 45, fontsize='10')\n",
    "    plt.yticks(fontsize='10')\n",
    "    plt.legend(title='')\n",
    "    plt.title(title)\n",
    "    set(ticklabels)\n",
    "    sns.reset_orig()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba66ef8a",
   "metadata": {},
   "source": [
    "## Plotting - Product Coverage\n",
    "- Functions to plot data by coverage. E.g. based on the geometries of each product. This does not account for duplicated data that can occur based on the gridding of products (e.g. overlapping of MGRS tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_and_cloud_raster(df, shape=(1000,1000)):\n",
    "    # convert each polygon of the of the datasets into a raster image (1's for data, 0's for non-data)\n",
    "    # and progressively add them all up, so the places with 1's data will accumulate into a frequency count\n",
    "    # replace the zeroes with nans to mask them out from the plot\n",
    "    crs = ccrs.SouthPolarStereo()\n",
    "    bounds = crs.boundary.bounds\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "    \n",
    "    freq_raster = np.zeros(shape)\n",
    "    cc_raster = np.zeros(shape) # approximate cloud cover perc for sentinel 2\n",
    "    for i in range(0,len(df)):\n",
    "        polygon = df['geometry'].iloc[i]\n",
    "        freq_raster += rasterize([(polygon, 1)], out_shape=shape, transform=transform)\n",
    "        if df['platformname'].iloc[0] == \"Sentinel-2\":\n",
    "            cc = df['cloudcoverpercentage'].iloc[i]\n",
    "            cc_raster += rasterize([(polygon, cc)], out_shape=shape, transform=transform)\n",
    "\n",
    "    #average the cc percentage\n",
    "    cc_raster = cc_raster/freq_raster\n",
    "    #mask out where nodata\n",
    "    cc_raster[freq_raster==0] = np.nan\n",
    "    freq_raster[freq_raster==0] = np.nan\n",
    "    return freq_raster, cc_raster\n",
    "\n",
    "def plot_frequency(df, title='', cbar_label='Frequency', cloud=False, shape=(1000,1000)):\n",
    "\n",
    "    freq_raster, cc_raster = get_freq_and_cloud_raster(df, shape=shape)\n",
    "    raster = cc_raster if cloud else freq_raster\n",
    "\n",
    "    crs = ccrs.SouthPolarStereo()\n",
    "    bounds = crs.boundary.bounds\n",
    "    east, west, south, north = -180, 180, -90, -50\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = [10,8]\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.set_extent((east, west, south, north+1), ccrs.PlateCarree())\n",
    "    ax.add_feature(cartopy.feature.LAND)\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    color = ax.imshow(raster, origin=\"upper\", extent=(bounds[0], bounds[2], bounds[1], bounds[3]), transform=ccrs.SouthPolarStereo())\n",
    "    ax.add_feature(cartopy.feature.COASTLINE)\n",
    "    cbar_max = int(raster[raster>-1].max())\n",
    "    plt.colorbar(color, ticks=np.linspace(0, cbar_max, 10, dtype=int), label=cbar_label)\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    plt.title(title)\n",
    "    return ax\n",
    "    \n",
    "def plot_frequency_side(raster, title='', cbar_label='Frequency', shape = (1000, 1000)):\n",
    "\n",
    "    crs = ccrs.SouthPolarStereo()\n",
    "    bounds = crs.boundary.bounds\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "    east, west, south, north = -180, 180, -90, -50\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = [14,3]\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.set_extent((0, 180, -90, -50), ccrs.PlateCarree())\n",
    "    ax.add_feature(cartopy.feature.LAND)\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    color = ax.imshow(raster, origin=\"upper\", extent=(bounds[0], bounds[2], bounds[1], bounds[3]), transform=ccrs.SouthPolarStereo())\n",
    "    cbar_max = int(raster[raster>-1].max())\n",
    "    plt.colorbar(color, ticks=np.linspace(0, cbar_max, 10, dtype=int), pad=0.1, label=cbar_label)\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    plt.title(title)\n",
    "    return ax\n",
    "\n",
    "def plot_multiple_frequency(df, group, sort_group='', title='', n_cols=2, cloud=False, cbar_label='Pass Frequency', shape=(1000,1000)):\n",
    "    \"\"\"Plot multiple graphs on same figures based on the multi levelled\n",
    "        dictionary passed. E.g. Products grouped by month or year\n",
    "\n",
    "    Args:\n",
    "        data (dict):\n",
    "        title (str): large title for plot\n",
    "        n_rows: number of rows\n",
    "    \"\"\"\n",
    "    sort_group = group if not sort_group else sort_group\n",
    "    df = df.sort_values(sort_group)\n",
    "\n",
    "    # calculate the size of the figure\n",
    "    n = df[group].nunique()\n",
    "    n_rows = math.ceil(n/n_cols)\n",
    "\n",
    "    # using the variable axs for multiple Axes\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols,\n",
    "                        subplot_kw={'projection': ccrs.SouthPolarStereo()},\n",
    "                        figsize=(n_cols*6,n_rows*5.5))\n",
    "    \n",
    "    # first create the plot raster for each category\n",
    "    # we can therefore get color to scale for all figures\n",
    "    raster_dict = {}\n",
    "    max_freq = 0\n",
    "    min_freq = 0\n",
    "    for cat in df[group].unique():\n",
    "        cat_data = df[df[group]==cat]\n",
    "        # get the frequency raster for each cat\n",
    "        freq_raster, cc_raster = get_freq_and_cloud_raster(cat_data, shape=shape)\n",
    "        if not cloud:\n",
    "            raster = freq_raster\n",
    "        else:\n",
    "            raster = cc_raster\n",
    "        #r_max = int(raster[raster>-1].max()) # max\n",
    "        r_max = int(np.percentile(raster[raster>-1],98)) #percentile \n",
    "        max_freq = r_max if (r_max > max_freq) else max_freq\n",
    "        r_min = int(raster[raster>-1].min()) \n",
    "        min_freq = r_min if (r_min < min_freq) else min_freq\n",
    "        raster_dict[cat] = raster\n",
    "    \n",
    "    crs = ccrs.SouthPolarStereo()\n",
    "    bounds = crs.boundary.bounds\n",
    "    east, west, south, north = -180, 180, -90, -50\n",
    "    \n",
    "    # iterate through the product dict\n",
    "    count = 0\n",
    "    print(df[group].unique())\n",
    "    for cat in df[group].unique():\n",
    "        r = math.floor((count)/n_cols)\n",
    "        c = count % n_cols\n",
    "        ax_i = (r,c) if ((n_cols > 1) and (n_rows>1)) else count # only a single index needed if no cols\n",
    "        # get product data for each catagory\n",
    "        n_products = len(df[df[group]==cat])\n",
    "        raster = raster_dict[cat]\n",
    "        ax[ax_i].set_extent((east, west, south, north), ccrs.PlateCarree())\n",
    "        ax[ax_i].add_feature(cartopy.feature.LAND)\n",
    "        ax[ax_i].add_feature(cartopy.feature.OCEAN)\n",
    "        ax[ax_i].title.set_text(f'{cat} ({n_products:,} products)')\n",
    "        color = ax[ax_i].imshow(raster, \n",
    "                                origin=\"upper\", \n",
    "                                extent=(bounds[0], bounds[2], bounds[1], bounds[3]), \n",
    "                                transform=ccrs.SouthPolarStereo(),\n",
    "                                vmin=min_freq,\n",
    "                                vmax=max_freq\n",
    "                                )\n",
    "        gl = ax[ax_i].gridlines(draw_labels=True)\n",
    "        ax[ax_i].add_feature(cartopy.feature.COASTLINE)\n",
    "        gl.xlabel_style['rotation']= 0\n",
    "        gl.xlabel_style['ha']= 'center'\n",
    "        gl.xlabel_style['va']= 'center'\n",
    "        count += 1\n",
    "\n",
    "    # add the colorbar for all plots\n",
    "    plt.tight_layout()\n",
    "    cbar_ax = fig.add_axes([0.05, -0.03, 0.9, 0.02])\n",
    "    fig.colorbar(color, cax=cbar_ax, label=cbar_label, orientation=\"horizontal\")\n",
    "    plt.suptitle(title, y=1.03, fontsize='x-large')\n",
    "\n",
    "    #delete subplot if uneven number\n",
    "    if count != (n_rows*n_cols):\n",
    "        if n_cols > 1:\n",
    "            fig.delaxes(ax[n_rows-1,n_cols-1])\n",
    "        else:\n",
    "            fig.delaxes(ax[n])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72111a85",
   "metadata": {},
   "source": [
    "## Plotting - Point Based Coverage\n",
    "- This plotting method uses randomly generated points to determine the number of unique passes over a given location. i.e. it accounts for the duplication of data from overlapping products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_points_in_bounds(filename, number, plot=True): \n",
    "    \"\"\" function to add a fixed number of points in a polygon. Points are spread equally across\n",
    "    latitudes and longitudes. TODO improve points generation spatially (i.e. the southern most\n",
    "    latitides have a smaller area than higher up the earth)\n",
    "    \"\"\"  \n",
    "    from shapely.geometry import Point, Polygon\n",
    "    import itertools\n",
    "\n",
    "    #open the spatial AOI\n",
    "    roi_gdf = gpd.read_file(filename)\n",
    "\n",
    "    minx, miny, maxx, maxy = roi_gdf.geometry.bounds.values[0]\n",
    "    xs = np.linspace(minx, maxx, num=number)\n",
    "    ys = np.linspace(miny, maxy, num=number)\n",
    "    #scale number for y\n",
    "    y_number = int(number * (abs(miny-maxy)/abs(minx-maxx)))\n",
    "    ys = np.linspace(miny, maxy, num=y_number)\n",
    "    points = list(itertools.product(xs, ys))\n",
    "    print(len(points))\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['points'] = points\n",
    "    df['points'] = df['points'].apply(Point)\n",
    "    points_gdf = gpd.GeoDataFrame(df, geometry='points', crs=\"EPSG:4326\")\n",
    "    Sjoin = gpd.tools.sjoin(points_gdf, roi_gdf, predicate=\"within\", how='left')\n",
    "    # # Keep points in \"myPoly\"\n",
    "    points_in_poly = Sjoin.intersection(roi_gdf['geometry'].values[0]).to_crs(3031)\n",
    "\n",
    "    # Plot result\n",
    "    if plot:\n",
    "        base = roi_gdf['geometry'].plot(linewidth=1, edgecolor=\"black\")\n",
    "        points_in_poly.plot(ax=base, linewidth=1, color=\"black\", markersize=8)\n",
    "        plt.show()\n",
    "        \n",
    "    return points_in_poly\n",
    "\n",
    "def calculate_valid_intersections(df, points_df, date_col='ingestiondate', min_revisit_time=10, plot=False):\n",
    "\n",
    "    print('Finding point based intersections for plotting')\n",
    "    # Build spatial index\n",
    "    spatial_index = STRtree(df.geometry)\n",
    "    # Create an empty GeoDataFrame to store the intersections for the current polygon\n",
    "    intersections = []\n",
    "    # Iterate over each polygon in the DataFrame\n",
    "    from tqdm import tqdm\n",
    "    for p in tqdm(points_df):\n",
    "        # Find potential intersecting polygons using the spatial index\n",
    "        potential_intersections = spatial_index.query(p)\n",
    "        # Check for intersections with potential polygons\n",
    "        for j in potential_intersections:\n",
    "             if p.intersects(df.geometry.iloc[j]):\n",
    "                row_data = df.iloc[j]\n",
    "                date = row_data[date_col]\n",
    "                if row_data.platformname == 'Sentinel-2':\n",
    "                    cc = row_data.cloudcoverpercentage\n",
    "                    sensoropmode = 'MSI'\n",
    "                    polarisation = 'NA'\n",
    "                    if df['producttype'].values[0] == 'S2MSI2A':\n",
    "                        tileid = row_data.identifier.split('_')[5]\n",
    "                    else:\n",
    "                        tileid = row_data.tileid\n",
    "                    \n",
    "                else:\n",
    "                    cc = 0\n",
    "                    tileid=''\n",
    "                    sensoropmode = row_data.sensoroperationalmode\n",
    "                    polarisation = row_data.polarisationmode\n",
    "                intersections.append({\n",
    "                    'intersectionpoint':p,\n",
    "                    'intersectionpointstr':str(p),\n",
    "                    'intersectionpoint_x':p.x,\n",
    "                    'intersectionpoint_y':p.y,\n",
    "                    date_col: row_data[date_col],\n",
    "                    'cloudcoverpercentage': cc,\n",
    "                    'polygon': row_data.geometry,\n",
    "                    'tileid': tileid,\n",
    "                    'relativeorbitnumber': row_data.relativeorbitnumber,\n",
    "                    'orbitdirection': row_data.relativeorbitnumber,\n",
    "                    'orbitnumber': row_data.relativeorbitnumber,\n",
    "                    'month_name': row_data.month_name,\n",
    "                    'month': row_data.month,\n",
    "                    'year': row_data.year,\n",
    "                    'sensoroperationalmode': sensoropmode,\n",
    "                    'polarisationmode': polarisation,\n",
    "                })\n",
    "\n",
    "    #covert to dataframe \n",
    "    intersections = pd.DataFrame.from_dict(intersections)\n",
    "\n",
    "    # sort by point and date aquired\n",
    "    intersections = intersections.sort_values(by=['intersectionpointstr',date_col])\n",
    "\n",
    "    # calculate the days between observations at a given point\n",
    "    # replace na / first datapoint with placeholder revisit time\n",
    "    placeholder_dt = datetime.timedelta(days=5)\n",
    "    intersections['timebetweenobs'] = (intersections[date_col] - intersections[date_col].shift(1)).fillna(placeholder_dt)\n",
    "    \n",
    "    # The first observation for each point does not have another time to compare\n",
    "    intersections[intersections['intersectionpointstr']!=intersections['intersectionpointstr'].shift(1)]['timebetweenobs'] = placeholder_dt\n",
    "    intersections['daysbetweenobs'] = intersections['timebetweenobs'].dt.days.astype(float)\n",
    "    intersections['minutesbetweenobs'] = intersections['timebetweenobs'].dt.total_seconds().astype(int)/60\n",
    "    \n",
    "    # keep only valid revisit times, \n",
    "    # i.e. when a point is measure at least 'min_revisit_time' minutes apart\n",
    "    intersections = intersections[intersections['minutesbetweenobs']>min_revisit_time]\n",
    "    intersections = gpd.GeoDataFrame(intersections, geometry='intersectionpoint', crs=\"EPSG:3031\")\n",
    "\n",
    "    # sort by point and date aquired\n",
    "    intersections = intersections.sort_values(by=['intersectionpointstr',date_col])\n",
    "\n",
    "    if plot:\n",
    "        heatmap, xedges, yedges = np.histogram2d(\n",
    "        intersections.intersectionpoint_x, \n",
    "        intersections.intersectionpoint_y, \n",
    "        bins=100)\n",
    "        extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "        print(extent)\n",
    "\n",
    "        plt.clf()\n",
    "        plt.title('Heatmap (not freq count)')\n",
    "        plt.imshow(heatmap.T, extent=extent, origin='lower')\n",
    "        plt.colorbar(orientation='horizontal')\n",
    "        plt.show()\n",
    "\n",
    "    return intersections\n",
    "\n",
    "def summarise_intersections(intersections, group=''):\n",
    "\n",
    "    if group:\n",
    "        groupby = ['intersectionpoint',group]\n",
    "    else:\n",
    "        groupby = ['intersectionpoint']\n",
    "    \n",
    "    intrsection_summary = intersections.groupby(groupby).agg(\n",
    "        revisit_count=('intersectionpointstr','count'),\n",
    "        mean_revisit_mins=('minutesbetweenobs','mean'),\n",
    "        median_revisit_mins=('minutesbetweenobs','median'),\n",
    "        mean_cloudcover=('cloudcoverpercentage','mean'),\n",
    "        median_cloudcover=('cloudcoverpercentage','median'),\n",
    "    ).reset_index()\n",
    "    \n",
    "    return intrsection_summary\n",
    "\n",
    "def plot_intersection_frequency(intersections, plot_var, title='', cbar_label='',shape=(1000,1000), force_max_val='', cmap='viridis', fixed_vals=False, repeat_orbits=False):\n",
    "    \n",
    "    # summarise the intersections\n",
    "    intrsection_summary = summarise_intersections(intersections)\n",
    "    \n",
    "    crs = ccrs.SouthPolarStereo()\n",
    "    bounds = crs.boundary.bounds\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "\n",
    "    freq_raster = np.zeros(shape)\n",
    "    for i,row in intrsection_summary.iterrows():\n",
    "        point = row.intersectionpoint\n",
    "        count = row[plot_var]\n",
    "        new_rast = rasterize([(point, count)], out_shape=shape, transform=transform)\n",
    "        # replace the value where higher - i.e. get max value per pixel\n",
    "        r,c = np.where(new_rast>freq_raster)\n",
    "        freq_raster[(r,c)] = new_rast[(r,c)]\n",
    "\n",
    "    # plot the raster\n",
    "    freq_raster[freq_raster==0] = np.nan\n",
    "    raster = freq_raster #cc_raster if cloud else freq_raster\n",
    "\n",
    "    if force_max_val:\n",
    "        raster[raster>force_max_val] = force_max_val\n",
    "\n",
    "    if fixed_vals:\n",
    "        raster[raster<5] = 5\n",
    "        raster[(raster>5) & (raster <= 10)] = 10\n",
    "        raster[(raster>10) & (raster <= 20)] = 15\n",
    "        raster[(raster>20) & (raster <= 40)] = 20\n",
    "        raster[(raster>=40)] = 25\n",
    "\n",
    "    crs = ccrs.SouthPolarStereo()\n",
    "    bounds = crs.boundary.bounds\n",
    "    east, west, south, north = -180, 180, -90, -50\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = [10,8]\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.set_extent((east, west, south, north+1), ccrs.PlateCarree())\n",
    "    ax.add_feature(cartopy.feature.LAND)\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    color = ax.imshow(raster, origin=\"upper\", extent=(bounds[0], bounds[2], bounds[1], bounds[3]), transform=ccrs.SouthPolarStereo(), cmap=cmap)\n",
    "    ax.add_feature(cartopy.feature.COASTLINE)\n",
    "\n",
    "    if fixed_vals:\n",
    "        # fixed colors\n",
    "        import matplotlib.patches as mpatches\n",
    "        values = np.unique(raster.ravel())\n",
    "        colors = [color.cmap(color.norm(value)) for value in sorted(values)]\n",
    "        # create a patch (proxy artist) for every color \n",
    "        patches = []\n",
    "        labels = ['<5','5 to 10','10 to 20','20 to 40','>40']\n",
    "        print(values[0:-1])\n",
    "        for i in range(len(values[0:-1])):\n",
    "            patches.append(mpatches.Patch(color=colors[i], label=labels[i].format(l=values[i])))\n",
    "        # put those patched as legend-handles into the legend\n",
    "        plt.legend(handles=patches, loc='upper right', title='Observations')\n",
    "    else:\n",
    "        cbar_max = int(raster[raster>-1].max())\n",
    "        plt.colorbar(color, ticks=np.linspace(0, cbar_max, 10, dtype=int), label=cbar_label)\n",
    "\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiple_intersection_frequency(intersections, plot_var, group, n_cols=2, title='', cbar_label='',shape=(1000,1000)):\n",
    "    \n",
    "    # summarise the intersections\n",
    "    intrsection_summary = summarise_intersections(intersections, group=group)\n",
    "    \n",
    "    crs = ccrs.SouthPolarStereo()\n",
    "    bounds = crs.boundary.bounds\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "\n",
    "     # calculate the size of the figure\n",
    "    n = intersections[group].nunique()\n",
    "    print(n)\n",
    "    n_rows = math.ceil(n/n_cols)\n",
    "\n",
    "    # using the variable axs for multiple Axes\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols,\n",
    "                        subplot_kw={'projection': ccrs.SouthPolarStereo()},\n",
    "                        figsize=(n_cols*5,n_rows*4.5))\n",
    "    \n",
    "    # product count by group to get max and min for colorbar\n",
    "    minima = intrsection_summary[plot_var].min()\n",
    "    maxima = intrsection_summary[plot_var].max()\n",
    "\n",
    "    east, west, south, north = -180, 180, -90, -50\n",
    "    \n",
    "    # colorbar\n",
    "    import matplotlib.cm as cm\n",
    "    norm = matplotlib.colors.Normalize(vmin=minima, vmax=maxima, clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap=cm.viridis)\n",
    "    count = 0\n",
    "\n",
    "    groups = intersections[group].unique()\n",
    "    if 'January' in groups:\n",
    "        print('Months')\n",
    "        groups = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "    else:\n",
    "        print('Years')\n",
    "        groups = sorted(groups)\n",
    "    print(groups)\n",
    "    for g in groups:\n",
    "        g_intrsection_summary = intrsection_summary[intrsection_summary[group]==g]\n",
    "        raster = np.zeros(shape)\n",
    "        for i,row in g_intrsection_summary.iterrows():\n",
    "            \n",
    "            # data\n",
    "            point = row.intersectionpoint\n",
    "            plot_val = row[plot_var]\n",
    "            new_rast = rasterize([(point, plot_val)], out_shape=shape, transform=transform)\n",
    "            \n",
    "            # replace the value where higher - i.e. get max value per pixel\n",
    "            r_,c_ = np.where(new_rast>raster)\n",
    "            raster[(r_,c_)] = new_rast[(r_,c_)]\n",
    "\n",
    "        raster[raster==0] = np.nan\n",
    "        r = math.floor((count)/n_cols)\n",
    "        c = count % n_cols\n",
    "        ax_i = (r,c) if ((n_cols > 1) and (n_rows>1)) else count # only a single index needed if no cols\n",
    "        # get product data for each catagory\n",
    "        #n_products = g_intrsection_summary\n",
    "        ax[ax_i].set_extent((east, west, south, north), ccrs.PlateCarree())\n",
    "        ax[ax_i].add_feature(cartopy.feature.LAND)\n",
    "        ax[ax_i].add_feature(cartopy.feature.OCEAN)\n",
    "        ax[ax_i].title.set_text(f'{g}')\n",
    "        color = ax[ax_i].imshow(raster, \n",
    "                                origin=\"upper\", \n",
    "                                extent=(bounds[0], bounds[2], bounds[1], bounds[3]), \n",
    "                                transform=ccrs.SouthPolarStereo(),\n",
    "                                vmin=minima,\n",
    "                                vmax=maxima\n",
    "                                )\n",
    "        ax[ax_i].add_feature(cartopy.feature.COASTLINE)\n",
    "        gl = ax[ax_i].gridlines(draw_labels=True)\n",
    "        gl.xlabel_style['rotation']= 0\n",
    "        gl.xlabel_style['ha']= 'center'\n",
    "        gl.xlabel_style['va']= 'center'\n",
    "        count += 1\n",
    "\n",
    "    # add the colorbar for all plots\n",
    "    plt.tight_layout()\n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, 0.9, 0.04])\n",
    "    plt.colorbar(mapper, cax=cbar_ax, label=cbar_label, orientation=\"horizontal\")\n",
    "    plt.suptitle(title, y=1.03, fontsize='x-large')\n",
    "\n",
    "    #delete subplot if uneven number\n",
    "    if count != (n_rows*n_cols):\n",
    "        if n_cols > 1:\n",
    "            fig.delaxes(ax[n_rows-1,n_cols-1])\n",
    "        else:\n",
    "            fig.delaxes(ax[n])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bfef5aa",
   "metadata": {},
   "source": [
    "## Plotting - MGRS Grid Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mgrs_product_count(df, title='', cbar_label='Count of Products'):\n",
    "\n",
    "    #read in the mgrs tile \n",
    "    gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "    df_mgrs = gpd.read_file('S2A_OPER_GIP_TILPAR_MPC__20151209T095117_V20150622T000000_21000101T000000_B00.kml', driver='KML')\n",
    "    #df_mgrs = df_mgrs.set_crs(4326).to_crs(3031)\n",
    "\n",
    "    # create a tile id identifier for level2\n",
    "    if df['producttype'].values[0] == 'S2MSI2A':\n",
    "        df['tileid'] = df['identifier'].apply(lambda x : x.split('_')[5])\n",
    "        #'identifier': 'S2B_MSIL2A_20190218T155329_N0211_R025_T03CVK_20190218T211152',\n",
    "    \n",
    "    # product count\n",
    "    prod_count = df.groupby(['tileid'])['filename'].count().reset_index() \n",
    "    tile_count = prod_count.merge(df_mgrs, right_on='Name', left_on='tileid')\n",
    "    tile_count = tile_count.rename(columns={'filename':'filecount'})\n",
    "    tile_count = tile_count.sort_values('filecount')\n",
    "\n",
    "    crs = ccrs.PlateCarree()\n",
    "    shape = 1000, 1000\n",
    "    bounds = crs.boundary.bounds\n",
    "    east, west, south, north = -180, 180, -90, -50\n",
    "    transform = rasterio.transform.from_bounds(*bounds, *shape)\n",
    "\n",
    "    import matplotlib.cm as cm\n",
    "\n",
    "    minima = tile_count.filecount.min()\n",
    "    maxima = tile_count.filecount.max()\n",
    "\n",
    "    norm = matplotlib.colors.Normalize(vmin=minima, vmax=maxima, clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap=cm.viridis)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = [10,8]\n",
    "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "    ax.set_extent((east, west, south, north+1), ccrs.PlateCarree())\n",
    "    ax.add_feature(cartopy.feature.LAND)\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    g = [t.geoms[0] for t in tile_count.geometry.values]\n",
    "    count_vals = tile_count.filecount.values\n",
    "    c = []\n",
    "    for v in count_vals:\n",
    "        c.append(mapper.to_rgba(v))\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    ax.add_geometries(g, crs=ccrs.PlateCarree(), alpha=1, facecolor=c)\n",
    "    ax.add_feature(cartopy.feature.COASTLINE)\n",
    "    plt.colorbar(mapper, label=cbar_label)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiple_product_count(df, group, title='', n_cols=2, cbar_label='Count of Products'):\n",
    "\n",
    "    #read in the mgrs tile \n",
    "    gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "    df_mgrs = gpd.read_file('S2A_OPER_GIP_TILPAR_MPC__20151209T095117_V20150622T000000_21000101T000000_B00.kml', driver='KML')\n",
    "    #df_mgrs = df_mgrs.set_crs(4326).to_crs(3031)\n",
    "\n",
    "    # create a tile id identifier for level2\n",
    "    if df['producttype'].values[0] == 'S2MSI2A':\n",
    "        df['tileid'] = df['identifier'].apply(lambda x : x.split('_')[5][1:])\n",
    "        #'identifier': 'S2B_MSIL2A_20190218T155329_N0211_R025_T03CVK_20190218T211152',\n",
    "    \n",
    "    # calculate the size of the figure\n",
    "    n = df[group].nunique()\n",
    "    n_rows = math.ceil(n/n_cols)\n",
    "\n",
    "    # using the variable axs for multiple Axes\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols,\n",
    "                        subplot_kw={'projection': ccrs.SouthPolarStereo()},\n",
    "                        figsize=(n_cols*5,n_rows*4.5))\n",
    "    \n",
    "    # product count by group to get max and min for colorbar\n",
    "    prod_counts = df.groupby([group,'tileid'])['filename'].count().reset_index()\n",
    "    minima = prod_counts.filename.min()\n",
    "    maxima = prod_counts.filename.max()\n",
    "    import matplotlib.cm as cm\n",
    "\n",
    "    norm = matplotlib.colors.Normalize(vmin=minima, vmax=maxima, clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap=cm.viridis)\n",
    "    count = 0\n",
    "    \n",
    "    plot_grps = df[group].unique()\n",
    "    try:\n",
    "        # sort if numeric\n",
    "        int(plot_grps[0])\n",
    "        plot_grps = sorted(plot_grps)\n",
    "    except:\n",
    "        ...\n",
    "\n",
    "    if 'January' in plot_grps:\n",
    "        print('Trying to plot')\n",
    "        plot_grps = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "    for grp in plot_grps:\n",
    "        grp_df = df[df[group] == grp]\n",
    "        tile_count = grp_df.groupby([group,'tileid'])['filename'].count().reset_index()\n",
    "        tile_count = tile_count.merge(df_mgrs, right_on='Name', left_on='tileid')\n",
    "        tile_count = tile_count.rename(columns={'filename':'filecount'})\n",
    "        n_products = tile_count['filecount'].sum()\n",
    "        tile_count = tile_count.sort_values('filecount')\n",
    "        east, west, south, north = -180, 180, -90, -50\n",
    "        r = math.floor((count)/n_cols)\n",
    "        c = count % n_cols\n",
    "        ax_i = (r,c) if ((n_cols > 1) and (n_rows>1)) else count # only a single index needed if no cols\n",
    "        ax[ax_i].set_extent((east, west, south, north), ccrs.PlateCarree())\n",
    "        ax[ax_i].add_feature(cartopy.feature.LAND)\n",
    "        ax[ax_i].add_feature(cartopy.feature.OCEAN)\n",
    "        subtitle = f'{grp} ({n_products:,} products)'\n",
    "        ax[ax_i].title.set_text(subtitle)\n",
    "        print(subtitle)\n",
    "        g = [t.geoms[0] for t in tile_count.geometry.values]\n",
    "        count_vals = tile_count.filecount.values\n",
    "        c = []\n",
    "        for v in count_vals:\n",
    "            c.append(mapper.to_rgba(v))\n",
    "        ax[ax_i].add_geometries(g, crs=ccrs.PlateCarree(), alpha=1, facecolor=c)\n",
    "        ax[ax_i].add_feature(cartopy.feature.COASTLINE)\n",
    "        gl = ax[ax_i].gridlines(draw_labels=True)\n",
    "        gl.xlabel_style['rotation']= 0\n",
    "        gl.xlabel_style['ha']= 'center'\n",
    "        gl.xlabel_style['va']= 'center'\n",
    "        count += 1\n",
    "\n",
    "    # add the colorbar for all plots\n",
    "    print('Adding colorbar...')\n",
    "    plt.tight_layout()\n",
    "    cbar_ax = fig.add_axes([0.05, -0.05, 0.9, 0.04])\n",
    "    #fig.colorbar(color, cax=cbar_ax, label=cbar_label, orientation=\"horizontal\")\n",
    "    plt.colorbar(mapper, cax=cbar_ax, label=cbar_label, orientation=\"horizontal\")\n",
    "    plt.suptitle(title, y=1.02, fontsize='x-large')\n",
    "\n",
    "    #delete subplot if uneven number\n",
    "    if count != (n_rows*n_cols):\n",
    "        if n_cols > 1:\n",
    "            fig.delaxes(ax[n_rows-1,n_cols-1])\n",
    "        else:\n",
    "            fig.delaxes(ax[n])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5daa781",
   "metadata": {},
   "source": [
    "# Generate Points for Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_POINTS = 550\n",
    "points_in_roi = generate_points_in_bounds(roi_shape, N_POINTS, plot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ce40209",
   "metadata": {},
   "source": [
    "# Sentinel 1 GRD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37c91a18",
   "metadata": {},
   "source": [
    "## Load and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb42ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'metadata/Sentinel-1_GRD_-50N_products.json'\n",
    "product = filename.split('_')[1]\n",
    "\n",
    "# engineering\n",
    "df = pd.read_json(filename, orient='index')\n",
    "df = add_metadata(df, date_col='beginposition', max_date=MAX_DATE)\n",
    "df = filter_results_with_geojson(df, roi_shape, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96420aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_s1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d81eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_s1(df[df['year']==2022])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8319f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the minimum lat\n",
    "df.geometry.bounds.miny.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_month_product_summary(df)\n",
    "#df.groupby('sensoroperationalmode')['beginposition'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Sentinel-1 Level 1 GRD - Weekly Products' \n",
    "plot_timeseries_products(df, title=title, stack_col='sat_id', date_col='beginposition',count_freq='7D', plot_freq='1M')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "378d67b6",
   "metadata": {},
   "source": [
    "## EW (All)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4dc2fdf",
   "metadata": {},
   "source": [
    "### Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d989c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD EW (All Polarisation) Revisit Frequency by Year\"\n",
    "plot_multiple_frequency(\n",
    "    df[df['sensoroperationalmode']=='EW'], \n",
    "    group='year', \n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count',\n",
    "    shape=(1300,1300)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b74c97d",
   "metadata": {},
   "source": [
    "### Annual (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8829593",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD EW (All Polarisation) Revisit Frequency (2022)\"\n",
    "plot_frequency(\n",
    "    df[(df['sensoroperationalmode']=='EW') & (df['year']==2022)], \n",
    "    title=title, \n",
    "    cbar_label='Revisit Count',\n",
    "    shape=(1300,1300)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1963a168",
   "metadata": {},
   "source": [
    "### Annual (2022) - Intersection based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support of above\n",
    "title = f\"Sentinel-1 GRD EW (All Polarisation) Revisit Frequency (2022)\"\n",
    "cbar_label = 'Revisit Count'\n",
    "intersections = calculate_valid_intersections(\n",
    "    df[(df['sensoroperationalmode']=='EW') & (df['year']==2022)], \n",
    "    points_df=points_in_roi,\n",
    "    date_col='beginposition')\n",
    "plot_intersection_frequency(intersections, \n",
    "                                     'revisit_count', \n",
    "                                     title=title, \n",
    "                                     cbar_label=cbar_label,\n",
    "                                     shape=(1000,1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8932510b",
   "metadata": {},
   "source": [
    "### Monthly (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3abd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD EW (All Polarisation) Revisit Frequency by Month (2022)\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='EW') & (df['year']==2022)], \n",
    "    group='month_name', \n",
    "    sort_group='month',\n",
    "    title=title, \n",
    "    n_cols=4,\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eda5447",
   "metadata": {},
   "source": [
    "## IW (All Polarisation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05724105",
   "metadata": {},
   "source": [
    "### Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac8d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD IW (All Polarisation) Revisit Frequency by Year\"\n",
    "plot_multiple_frequency(\n",
    "    df[df['sensoroperationalmode']=='IW'], \n",
    "    group='year', \n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0df31eeb",
   "metadata": {},
   "source": [
    "### Monthly (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD IW (All Polarisation) Revisit Frequency by Month (2022)\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='IW') & (df['year']==2022)], \n",
    "    group='month_name', \n",
    "    sort_group='month',\n",
    "    title=title, \n",
    "    n_cols=4\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38c5c7ab",
   "metadata": {},
   "source": [
    "## EW (HH HV Polarisation) - Polar Monitoring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b0fa4fb",
   "metadata": {},
   "source": [
    "### Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520678c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD EW (HH HV Polarisation) Revisit Frequency by Year\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='EW') & (df['polarisationmode']=='HH HV')], \n",
    "    group='year', \n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27547f6e",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD EW (HH HV Polarisation) Revisit Frequency by Month (2022)\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='EW') & (df['polarisationmode']=='HH HV') & (df['year']==2022)], \n",
    "    group='month_name', \n",
    "    sort_group='month',\n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f272512",
   "metadata": {},
   "source": [
    "## EW (HH Polarisation) - Polar Monitoring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e367d7bc",
   "metadata": {},
   "source": [
    "### Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e3a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD EW (HH Polarisation) Revisit Frequency by Year\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='EW') & (df['polarisationmode']=='HH')], \n",
    "    group='year', \n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7572a9fd",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d99086",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD EW (HH Polarisation) Revisit Frequency by Month (2022)\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='EW') & (df['polarisationmode']=='HH') & (df['year']==2022)], \n",
    "    group='month_name', \n",
    "    sort_group='month',\n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67056371",
   "metadata": {},
   "source": [
    "## IW (HH Polarisation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35f4f176",
   "metadata": {},
   "source": [
    "### Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD IW (HH Polarisation) Revisit Frequency by Year\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='IW') & (df['polarisationmode']=='HH')], \n",
    "    group='year', \n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74567d3b",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d41c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD IW (HH Polarisation) Revisit Frequency by Month (2022)\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='IW') & (df['polarisationmode']=='HH') & (df['year']==2022)], \n",
    "    group='month_name', \n",
    "    sort_group='month',\n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f0dcc43",
   "metadata": {},
   "source": [
    "## IW (VV VH Polarisation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a26af36c",
   "metadata": {},
   "source": [
    "### Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD IW (HH VH Polarisation) Revisit Frequency by Year\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='IW') & (df['polarisationmode']=='VV VH')], \n",
    "    group='year', \n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24506161",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68219dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD IW (HH VH Polarisation) Revisit Frequency by Month (2022)\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='IW') & (df['polarisationmode']=='VV VH') & (df['year']==2022)], \n",
    "    group='month_name', \n",
    "    sort_group='month',\n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "587281cd",
   "metadata": {},
   "source": [
    "## SM (All Polarisation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a672bf86",
   "metadata": {},
   "source": [
    "### Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40eb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD SM (All Polarisation) Revisit Count by Year\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['sensoroperationalmode']=='SM')], \n",
    "    group='year', \n",
    "    title=title, \n",
    "    n_cols=4, \n",
    "    cbar_label='Revisit Count'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7747bf9e",
   "metadata": {},
   "source": [
    "## Product Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc1a45dd",
   "metadata": {},
   "source": [
    "### IW / EW / SM(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD Revisit Frequency by Aquisition Mode (2022)\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['year']==2022)], \n",
    "    group='sensoroperationalmode', \n",
    "    title=title, \n",
    "    n_cols=3, \n",
    "    cbar_label='Revisit Count',\n",
    "    shape=(1200,1200)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a673cac6",
   "metadata": {},
   "source": [
    "## IW Polarisation Comparison (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD IW Revisit Frequency Comparison of Polarisation (2022)\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['year']==2022) & (df['sensoroperationalmode']=='IW')], \n",
    "    group='polarisationmode', \n",
    "    title=title, \n",
    "    n_cols=3, \n",
    "    cbar_label='Revisit Count',\n",
    "    shape=(1300,1300)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54d4ca8b",
   "metadata": {},
   "source": [
    "## EW Polarisation Comparison (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 GRD EW Revisit Frequency by Polarisation (2022)\"\n",
    "plot_multiple_frequency(\n",
    "    df[(df['year']==2022) & (df['sensoroperationalmode']=='EW')], \n",
    "    group='polarisationmode', \n",
    "    title=title, \n",
    "    n_cols=2, \n",
    "    cbar_label='Revisit Count'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53ca703",
   "metadata": {},
   "source": [
    "# Seninel 1 SLC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d9e41d",
   "metadata": {},
   "source": [
    "## Load and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "filename = f'metadata/Sentinel-1_SLC_-50N_products.json'\n",
    "product = filename.split('_')[1]\n",
    "\n",
    "# engineering\n",
    "df = pd.read_json(filename, orient='index')\n",
    "df = add_metadata(df, date_col='beginposition', max_date=MAX_DATE)\n",
    "df = filter_results_with_geojson(df, roi_shape, plot=True)\n",
    "#summarise_s1(df)\n",
    "summarise_s1(df[df['year']==2022])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baddea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_s1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_month_product_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8941c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Sentinel-1 Level 1 SLC - Weekly Products' \n",
    "plot_timeseries_products(df, title=title, stack_col='sat_id', date_col='beginposition',count_freq='7D', plot_freq='1M')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5ccf828",
   "metadata": {},
   "source": [
    "## Product Comparison (2022)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "624331bd",
   "metadata": {},
   "source": [
    "### Aquisition Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 SLC Revisit Frequency by Aquisition Mode (2022)\"\n",
    "cbar_label = 'Revisit Count'\n",
    "intersections = calculate_valid_intersections(\n",
    "    df[df['year']==2022], \n",
    "    points_df=points_in_roi,\n",
    "    date_col='beginposition')\n",
    "plot_multiple_intersection_frequency(intersections, \n",
    "                                     'revisit_count', \n",
    "                                     group='sensoroperationalmode', \n",
    "                                     n_cols=4, title=title, cbar_label=cbar_label,shape=(1100,1100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f314153f",
   "metadata": {},
   "source": [
    "### Polarisation (IW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0149bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 SLC IW Revisit Frequency by Polarisation (2022)\"\n",
    "cbar_label = 'Revisit Count'\n",
    "intersections = calculate_valid_intersections(\n",
    "    df[(df['year']==2022) & (df['sensoroperationalmode']=='IW')], \n",
    "    points_df=points_in_roi,\n",
    "    date_col='beginposition')\n",
    "plot_multiple_intersection_frequency(intersections, \n",
    "                                     'revisit_count', \n",
    "                                     group='polarisationmode', \n",
    "                                     n_cols=3, title=title, cbar_label=cbar_label,shape=(1100,1100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97dcba81",
   "metadata": {},
   "source": [
    "## IW (All Polarisation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4177e983",
   "metadata": {},
   "source": [
    "### IW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122edffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 SLC IW (All Polarisation) Revisit Frequency by Year\"\n",
    "cbar_label = 'Revisit Count'\n",
    "intersections = calculate_valid_intersections(\n",
    "    df[(df['sensoroperationalmode']=='IW')], \n",
    "    points_df=points_in_roi,\n",
    "    date_col='beginposition')\n",
    "plot_multiple_intersection_frequency(intersections, \n",
    "                                     'revisit_count', \n",
    "                                     group='year', \n",
    "                                     n_cols=4, title=title, cbar_label=cbar_label,shape=(1100,1100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faabc657",
   "metadata": {},
   "source": [
    "### (IW 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-1 SLC IW (All Polarisation) Revisit Frequency (2022)\"\n",
    "cbar_label = 'Revisit Count'\n",
    "# intersections = calculate_valid_intersections(\n",
    "#     df[(df['sensoroperationalmode']=='IW') & (df['year']==2022)], \n",
    "#     points_df=points_in_roi,\n",
    "#     date_col='beginposition')\n",
    "plot_intersection_frequency(intersections, \n",
    "                                     'revisit_count', \n",
    "                                     title=title, \n",
    "                                     cbar_label=cbar_label,\n",
    "                                     shape=(1300,1300))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c66702c",
   "metadata": {},
   "source": [
    "# Sentinel-2 Level 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4701cda1",
   "metadata": {},
   "source": [
    "## Load and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f927bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "filename = f'metadata/Sentinel-2_S2MSI1C_-50N_products.json'\n",
    "product = filename.split('_')[1]\n",
    "with open(filename, 'r') as f:\n",
    "     df = json.load(f)\n",
    "\n",
    "# # engineering\n",
    "df = pd.DataFrame.from_dict(df, orient='index')\n",
    "df = add_metadata(df, date_col='beginposition', max_date=MAX_DATE)\n",
    "print(list(df))\n",
    "df = filter_results_with_geojson(df, roi_shape, plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, y = year_month_product_summary(df)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e48f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_footprint_map(df.head(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sizeGB'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b7fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a cloud coverage category based on - https://landsat.usgs.gov/landsat-8-cloud-cover-assessment-validation-data\n",
    "df['cloud_cover_category'] = df['cloudcoverpercentage'].apply(\n",
    "    lambda x : 'Clear (<35%)' if x < 35 else ('Cloudy (>65%)' if x>65 else 'MidClouds (35-65%)'))\n",
    "\n",
    "import pvlib\n",
    "def add_sun_zenith(df, date_col='beginposition'):\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df[date_col].dt.tz_localize('UTC')\n",
    "    df['centroid_x'] = df['geometry_4326'].apply(lambda x : x.centroid.x)\n",
    "    df['centroid_y'] = df['geometry_4326'].apply(lambda x : x.centroid.y)\n",
    "    z = pvlib.solarposition.get_solarposition(df[date_col], df.centroid_y, df.centroid_x, altitude=0)\n",
    "    z.columns = ['sun_' + x for x in z.columns.values]\n",
    "    z = z['sun_zenith'].to_dict()\n",
    "    df['sun_zenith'] = df[date_col].map(z)\n",
    "    return df\n",
    "\n",
    "# add sun zenith\n",
    "df = add_sun_zenith(df, date_col='datatakesensingstart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Sentinel-2 Level 1C - Weekly Products' \n",
    "plot_timeseries_products(df, title=title, stack_col='sat_id', date_col='beginposition',count_freq='7D', plot_freq='1M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9dc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['centroid'] = df['geometry_4326'].apply(lambda x : x.centroid)\n",
    "df['centroid_x'] = df['centroid'].apply(lambda x : x.x)\n",
    "df['centroid_y'] = df['centroid'].apply(lambda x : x.y)\n",
    "\n",
    "bins = [-90, -85, -80, -75, -70, -65, -60, -55, -50, -45]\n",
    "labels = ['85-90', '80-85', '75-80', '70-75', '65-70', '60-65', '55-60', '50-55', 'less than 50']\n",
    "df['lon_category'] = pd.cut(x = df['centroid_y'], bins = bins, labels = labels, include_lowest = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf67b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sun_zenith_over_70'] = df['sun_zenith'] > 70\n",
    "df['sun_zenith_over_88'] = df['sun_zenith'] > 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58843e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenith_by_lat = df[df['year'] ==2022].groupby('lon_category').agg(\n",
    "    count=('sun_zenith_over_70','count'),\n",
    "    sun_zenith_over_70=('sun_zenith_over_70','sum'),\n",
    "    sun_zenith_over_88=('sun_zenith_over_88','sum'),\n",
    ").reset_index()\n",
    "zenith_by_lat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfb89914",
   "metadata": {},
   "source": [
    "### Cloud Cover by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d463a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['cloud_cover_category'])['filename'].count() / (df.groupby(['cloud_cover_category'])['filename'].count().sum())\n",
    "#list(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10e1277f",
   "metadata": {},
   "source": [
    "### Sun Zenith Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Sentinel 2 Level 1 Distribution of Product Sun Zenith Angles (2016-12 to 2023-06)'\n",
    "ax = df['sun_zenith'].plot(kind='hist', title=title, bins=20, figsize=(10,5))\n",
    "ax.axvline(x=70, color='red', linestyle='--')\n",
    "ax.set_xlabel('Sun Zenith Angle (SZA)')\n",
    "ax.set_ylabel('Count of Products')\n",
    "#ax.annotate('Maximum SZA adhering to Sen2Cor\\nLevel-2 Processing Assumptions (70)', (71, 200_000), color='red')\n",
    "ax.annotate('70', (65, 250_000), color='red')\n",
    "ax.set_xlim([0,100])\n",
    "\n",
    "print(sum(df[(df['year']==2022)]['sun_zenith']>70))\n",
    "print(len(df[(df['year']==2022)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f7258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sun_zenith_over_70'] = df['sun_zenith']>70\n",
    "summary_22 = df[(df['year']==2022)].groupby(['year','month']).agg(\n",
    "    count_total_products=('sun_zenith','count'),\n",
    "    count_zenith_over_70=('sun_zenith_over_70','sum'),\n",
    "    mean_zenith_value=('sun_zenith','mean'),\n",
    "    median_zenith_value=('sun_zenith','median'),\n",
    ").reset_index()\n",
    "summary_22"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cba348d0",
   "metadata": {},
   "source": [
    "## Product Count by MGRS Tile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0806a88",
   "metadata": {},
   "source": [
    "### Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-2 Level-1C by Year\"\n",
    "plot_multiple_product_count(df, n_cols=3, group='year', title=title, cbar_label='Count of Products')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30c98c4b",
   "metadata": {},
   "source": [
    "### Annual (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a50c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-2 Level-1C Product Count by MGRS tile (2022)\"\n",
    "plot_mgrs_product_count(df[df['year']==2022], title=title, cbar_label='Count of Products')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "333e1e17",
   "metadata": {},
   "source": [
    "### Monthly (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-2 Level-1C by Month (2022)\"\n",
    "plot_multiple_product_count(df[df['year']==2022], \n",
    "                            n_cols=4, \n",
    "                            group='month_name', \n",
    "                            title=title, cbar_label='Count of Products')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28806a0c",
   "metadata": {},
   "source": [
    "## Intersection based"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16e08857",
   "metadata": {},
   "source": [
    "### Annual Revisit Count (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05debdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Sentinel-2 Level 1C Revisit Frequency (2022)'\n",
    "cbar_label = 'Revisit Count'\n",
    "df.geometry = df.geometry.buffer(0)\n",
    "intersections = calculate_valid_intersections(df[df['year']==2022], points_df=points_in_roi, date_col='beginposition')\n",
    "plot_intersection_frequency(intersections, plot_var='revisit_count', title=title, cbar_label=cbar_label, shape=(1000,1000))\n",
    "#plot_intersection_frequency(intersections, plot_var='revisit_count', title=title, cbar_label=cbar_label, shape=(220,220), force_max_val=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224aa15",
   "metadata": {},
   "source": [
    "### Monthly (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-2 Level-1C Revisit Frequency by Month (2022)\"\n",
    "cbar_label = 'Revisit Count'\n",
    "intersections = calculate_valid_intersections(\n",
    "    df[(df['year']==2022)], \n",
    "    points_df=points_in_roi,\n",
    "    date_col='beginposition')\n",
    "plot_multiple_intersection_frequency(intersections, \n",
    "                                     'revisit_count', \n",
    "                                     group='month_name', \n",
    "                                     n_cols=4, \n",
    "                                     title=title, \n",
    "                                     cbar_label=cbar_label,shape=(1000,1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20b89876",
   "metadata": {},
   "source": [
    "### Cloud Cover (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Sentinel-2 Level 1C Approximate Cloud Cover (2022)'\n",
    "cbar_label = 'Mean Observation Cloud Cover (%)'\n",
    "#intersections = calculate_valid_intersections(df[df['year']==2022], points_df=points_in_roi, date_col='beginposition')\n",
    "plot_intersection_frequency(intersections, plot_var='mean_cloudcover', title=title, cbar_label=cbar_label, shape=(1000,1000), cmap='plasma')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ae35a07",
   "metadata": {},
   "source": [
    "### Cloudfree revisits (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af335da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Sentinel-2 Level 1C Predominantly Cloud Free (<35%) Observations (2022)'\n",
    "cbar_label = 'Revisit Count'\n",
    "intersections = calculate_valid_intersections(df[(df['year']==2022) & (df['cloudcoverpercentage']<35)], \n",
    "                                              points_df=points_in_roi, \n",
    "                                              date_col='beginposition')\n",
    "plot_intersection_frequency(intersections, \n",
    "                            plot_var='revisit_count', \n",
    "                            title=title, \n",
    "                            cbar_label=cbar_label, \n",
    "                            shape=(1000,1000), \n",
    "                            cmap='plasma', \n",
    "                            fixed_vals=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5af9cac",
   "metadata": {},
   "source": [
    "# Sentinel-2 Level 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f38bba9b",
   "metadata": {},
   "source": [
    "## Load and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "filename = f'metadata/Sentinel-2_S2MSI2A_-50N_products.json'\n",
    "product = filename.split('_')[1]\n",
    "with open(filename, 'r') as f:\n",
    "     df = json.load(f)\n",
    "\n",
    "# # engineering\n",
    "df = pd.DataFrame.from_dict(df, orient='index')\n",
    "df = add_metadata(df, date_col='beginposition', max_date=MAX_DATE)\n",
    "print(list(df))\n",
    "df = filter_results_with_geojson(df, roi_shape, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, y = year_month_product_summary(df)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sizeGB'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea472fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Sentinel-2 Level 2A - Weekly Products' \n",
    "plot_timeseries_products(df, title=title, stack_col='sat_id', date_col='beginposition',count_freq='7D', plot_freq='1M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a cloud coverage category based on - https://landsat.usgs.gov/landsat-8-cloud-cover-assessment-validation-data\n",
    "df['cloud_cover_category'] = df['cloudcoverpercentage'].apply(\n",
    "    lambda x : 'Clear (<35%)' if x < 35 else ('Cloudy (>65%)' if x>65 else 'MidClouds (35-65%)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Sentinel-1 Level 1 SLC - Weekly Products' \n",
    "plot_timeseries_products(df, title=title, stack_col='sat_id', date_col='beginposition',count_freq='7D', plot_freq='1M')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4b70cea",
   "metadata": {},
   "source": [
    "### Sun Zenith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02680c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary by year\n",
    "df['illuminationzenithangle'].plot(kind='hist')\n",
    "df['illuminationzenithangle_over70'] = df['illuminationzenithangle'] > 70\n",
    "summary = df.groupby('year').agg(\n",
    "    count_total_products=('illuminationzenithangle','count'),\n",
    "    count_zenith_over_70=('illuminationzenithangle_over70','sum'),\n",
    "    mean_zenith_value=('illuminationzenithangle','mean'),\n",
    "    median_zenith_value=('illuminationzenithangle','median'),\n",
    ").reset_index()\n",
    "summary['perc_products_zenith_over_70'] = 100*(summary['count_zenith_over_70']/summary['count_total_products']).round(2)\n",
    "summary\n",
    "\n",
    "# 2022 summary by month\n",
    "df_2022 = df[df['year']==2022]\n",
    "summary_22 = df_2022.groupby(['year','month']).agg(\n",
    "    count_total_products=('illuminationzenithangle','count'),\n",
    "    count_zenith_over_70=('illuminationzenithangle_over70','sum'),\n",
    "    mean_zenith_value=('illuminationzenithangle','mean'),\n",
    "    median_zenith_value=('illuminationzenithangle','median'),\n",
    ").reset_index()\n",
    "\n",
    "summary_22['perc_products_zenith_over_70'] = 100*(summary_22['count_zenith_over_70']/summary_22['count_total_products']).round(2)\n",
    "summary[summary['year'].isin([2022,2023])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e3db3d6",
   "metadata": {},
   "source": [
    "## Product Count by MGRS Tile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c6bc984",
   "metadata": {},
   "source": [
    "### Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65988bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-2 Level-2A by Year\"\n",
    "plot_multiple_product_count(df, n_cols=3, group='year', title=title, cbar_label='Count of Products')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f988599f",
   "metadata": {},
   "source": [
    "### Annual (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fab8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-2 Level-2A Product Count by MGRS tile (2022)\"\n",
    "plot_mgrs_product_count(df[df['year']==2022], title=title, cbar_label='Count of Products')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ce78228",
   "metadata": {},
   "source": [
    "### Monthly (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce3931",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"Sentinel-2 Level-2A by Month (2022)\"\n",
    "plot_multiple_product_count(df[df['year']==2022], \n",
    "                            n_cols=4, \n",
    "                            group='month_name', \n",
    "                            title=title, cbar_label='Count of Products')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b5a40dc",
   "metadata": {},
   "source": [
    "## Intersection based"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56dad461",
   "metadata": {},
   "source": [
    "### Annual Revisit Count (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0495d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Sentinel-2 Level 2A Revisit Frequency (2022)'\n",
    "cbar_label = 'Revisit Count'\n",
    "df.geometry = df.geometry.buffer(0)\n",
    "intersections = calculate_valid_intersections(df[df['year']==2022], points_df=points_in_roi, date_col='beginposition')\n",
    "plot_intersection_frequency(intersections, plot_var='revisit_count', title=title, cbar_label=cbar_label, shape=(1000,1000))\n",
    "#plot_intersection_frequency(intersections, plot_var='revisit_count', title=title, cbar_label=cbar_label, shape=(220,220), force_max_val=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e00d531",
   "metadata": {},
   "source": [
    "### Cloud Cover (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Sentinel-2 Level 2A Approximate Cloud Cover (2022)'\n",
    "cbar_label = 'Mean Observation Cloud Cover (%)'\n",
    "plot_intersection_frequency(intersections, plot_var='mean_cloudcover', title=title, cbar_label=cbar_label, shape=(1000,1000), cmap='plasma')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdaa430d",
   "metadata": {},
   "source": [
    "### Cloudfree revisits (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39961951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appriximate cloudcover with overlapping products\n",
    "title = f'Sentinel-2 Level 2A Predominantly Cloud Free (<35%) Observations (2022)'\n",
    "cbar_label = 'Revisit Count'\n",
    "intersections = calculate_valid_intersections(df[(df['year']==2022) & (df['cloudcoverpercentage']<35)], \n",
    "                                              points_df=points_in_roi, \n",
    "                                              date_col='beginposition')\n",
    "plot_intersection_frequency(intersections, plot_var='revisit_count', title=title, cbar_label=cbar_label, shape=(1000,1000), cmap='plasma', fixed_vals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a926a1d",
   "metadata": {},
   "source": [
    "# Sentinel-3 OLCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "filename = f'metadata/Sentinel-3_OLCI_-50N_products.json'\n",
    "product = filename.split('_')[1]\n",
    "with open(filename, 'r') as f:\n",
    "     df = json.load(f)\n",
    "\n",
    "# # engineering\n",
    "df = pd.DataFrame.from_dict(df, orient='index')\n",
    "df = add_metadata(df, date_col='beginposition', max_date=MAX_DATE, CRS=3031)\n",
    "#print(list(df))\n",
    "#df = filter_results_with_geojson(df, roi_shape, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d2ff0",
   "metadata": {},
   "source": [
    "## Product Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94180ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both level 1 and level 2 products are in the same file\n",
    "# products - https://sentinels.copernicus.eu/ca/web/sentinel/user-guides/sentinel-3-olci/processing-levels\n",
    "# !! LFR/LRR seems to include coverage over water, seen in cop scihub\n",
    "# revisit time - https://sentinels.copernicus.eu/ca/web/sentinel/user-guides/sentinel-3-olci/coverage\n",
    "df[['productlevel','producttype']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8796bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df['producttype']=='OL_2_LFR___'] # full resolution\n",
    "df = df[df['producttype']=='OL_2_LRR___'] # reduced resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898fa1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'{filename} - Weekly Products' \n",
    "sf.plot_timeseries_products(df, title=title, stack_col='sat_id', date_col='beginposition',count_freq='7D', plot_freq='1M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3cef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_sum, df_y_sum = year_month_product_summary(df)\n",
    "df_y_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b49c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
